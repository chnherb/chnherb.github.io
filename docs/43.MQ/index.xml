<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Herbdocs – MQ</title><link>/docs/43.MQ/</link><description>Recent content in MQ on Herbdocs</description><generator>Hugo -- gohugo.io</generator><atom:link href="/docs/43.MQ/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: 深入理解Kafka：核心设计与实践原理</title><link>/docs/43.MQ/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Kafka%E6%A0%B8%E5%BF%83%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E8%B7%B5%E5%8E%9F%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/43.MQ/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Kafka%E6%A0%B8%E5%BF%83%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E8%B7%B5%E5%8E%9F%E7%90%86/</guid><description>
&lt;h1 id="01-初始kafka">01 初始Kafka&lt;/h1>
&lt;p>“扮演“的三大角色：&lt;/p>
&lt;p>1、消息系统：解耦、冗余存储、流量削峰、缓冲、异步通信、扩展性、可恢复性等。此外，kafka还提供了消息顺序性保障及回溯消费的功能。&lt;/p>
&lt;p>2、存储系统：kafka把消息持久化到磁盘，相比于其他基于内存存储的系统而言，有效地降低了数据丢失的风险。得益于kafka的消息持久化功能和多副本机制，可以把kafka作为长期的数据存储系统来使用，只需要把对应的数据保留策略设置为”永久“或启用主体的日志压缩功能即可。&lt;/p>
&lt;p>3、流式处理平台&lt;/p>
&lt;h2 id="1-1-基本概念">1.1 基本概念&lt;/h2>
&lt;p>一个典型的Kafka体系架构包括若干Producer、若干Broker、若干Consumer，以及一个ZooKeeper集群。&lt;/p>
&lt;p>（1）Producer：生产者，发消息的一方。负责创建消息，然后投递到Kafka中。&lt;/p>
&lt;p>（2）Consumer：消费者，也就是接收消息的一方。连接到Kafka上并接收消息，进而进行相应的业务逻辑处理。&lt;/p>
&lt;p>（3）Broker：服务代理节点。可以简单看作成一个独立的Kafka服务节点或Kafka服务实例。&lt;/p>
&lt;p>主题分区。kafka保证的是分区有序而不是主题有序。&lt;/p>
&lt;p>Kafka的分区可以分布在不同的服务器（broker）上，一个主题可以横跨多个broker，以此来提供比单个broker更强大的性能。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_kafka_1.png" alt="20221231_kafka_1.png">&lt;/p>
&lt;p>Kafka为分区引入了多副本（Replica）机制，通过增加副本数量可以提升容灾能力。同一分区的不同副本中保存的是相同的消息（同一时刻，副本之间并非完全一样），副本之间是“一主多从”的关系，其中leader副本负责处理读写请求，follower副本只负责与leader副本消息同步。副本处于不同的broker中，当leader副本出现故障时，从follower副本中重新选举新的leader副本对外提供服务。&lt;/p>
&lt;p>分区中的所有副本统称为 AR（Assigned Replicas）。所有与leader副本保持一定程度同步的副本（包括leader副本在内）组成ISR（In-Sync Replicas）。与leader副本同步滞后过多的副本（不包括leader副本）组成OSR（Out-of-Sync Replicas），&lt;strong>AR=ISR+OSR&lt;/strong>。正常情况下，所有follower副本与leader副本保持一定程度的同步，即AR=ISR。&lt;/p>
&lt;p>HW(High Watermark)：高水位。消费者只能拉取这个offset之前的消息。&lt;/p>
&lt;p>LEO(Log End Offset)：标识当前日志文件中下一条待写入消息的offset。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_kafka_2.png" alt="20221231_kafka_2.png">&lt;/p>
&lt;p>同步消息时（从leader副本到follower副本），不同的follower的同步效率不尽相同，HW取所有LEO中的最小值。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_kafka_3.png" alt="20221231_kafka_3.png">&lt;/p>
&lt;h2 id="1-2-安装与配置">1.2 安装与配置&lt;/h2>
&lt;p>1、JDK的安装与配置&lt;/p>
&lt;p>2、ZooKeeper安装与配置&lt;/p>
&lt;p>ZooKeeper实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master选举、配置维护等功能。ZooKeeper中共有3中角色：leader、follower和observer。observer不参与投票，默认情况下ZooKeeper中只有leader和follower两种角色。&lt;/p>
&lt;p>3、Kafka的安装与配置&lt;/p>
&lt;h2 id="1-3-生产与消费">1.3 生产与消费&lt;/h2>
&lt;p>shell和Java编程&lt;/p>
&lt;h2 id="1-4-服务端参数配置">1.4 服务端参数配置&lt;/h2>
&lt;p>1、zookeeper.connect 该参数指明broker要连接的ZooKeeper集群的服务地址（包含端口号），没有默认值，为必填项。如localhost:2181，如集群有多个节点，用多个逗号将每个节点隔开。（升华：复用ZooKeeper集群，增加chroot路径）&lt;/p>
&lt;p>2、 listeners 该参数指明broker监听客户端连接的地址列表，即为客户端要连接的broker的入口地址列表，配置格式为protocol1://hostname1:port1, protocol2://hostname2:port2，其中protocol代表协议类型，Kafka目前支持PLAINTEXT、SSL、SASL_SSL等，如未开启安全认证，使用简单的PLAINTEXT即可。&lt;/p>
&lt;p>3、 broker.id Kafka集群中broker的唯一标识，默认值为-1。&lt;/p>
&lt;p>4、log.dir和log.dirs Kafka把所有的消息都保存在磁盘上，而这两个参数用来配置Kafka日志文件存放的根目录。前者配置单个根目录，后者配置多个根目录（以逗号隔开），但没有严格限制，两者都可配置单个/多个根目录。后者优先级比前者高。前者默认值：/tmp/kafka-logs。&lt;/p>
&lt;p>5、message.max.bytes 该参数用来指定broker所能接收消息的最大值，默认值为1000012(B)，约等于976.6KB。如果Producer发送的消息大于该值，会报出RecordTooLargeException的异常。修改需考虑max.request.size（客户端参数）、max.message.bytes（topic端参数）等的影响，建议另考虑分拆消息的可行性。&lt;/p>
&lt;h2 id="1-5-总结">1.5 总结&lt;/h2>
&lt;h1 id="02-生产者">02 生产者&lt;/h1>
&lt;h2 id="2-1-客户端开发">2.1 客户端开发&lt;/h2>
&lt;p>正常的生产逻辑步骤：&lt;/p>
&lt;p>1、配置生产者客户端参数及创建相应的生产者实例；&lt;/p>
&lt;p>2、构建待发送的消息；&lt;/p>
&lt;p>3、发送消息；&lt;/p>
&lt;p>4、关闭生产者实例。&lt;/p>
&lt;h3 id="2-1-2-消息的发送">2.1.2 消息的发送&lt;/h3>
&lt;p>发送消息的三种模式：发后即忘（fire-and-forget）、同步（sync）及异步（async）。&lt;/p>
&lt;h3 id="2-1-3-序列化">2.1.3 序列化&lt;/h3>
&lt;h3 id="2-1-4-分区器">2.1.4 分区器&lt;/h3>
&lt;p>send()方法发往broker的过程中，有可能需要经过拦截器（Interceptor）（非必须）、序列化器（Serializer）（必须）和分区器（Partitioner）的一系列作用之后才能被真正地发往broker。如果ProducerRecord中指定了partition字段，就不需要分区器，因为该字段代表了分区号。&lt;/p>
&lt;h3 id="2-1-5-生产者拦截器">2.1.5 生产者拦截器&lt;/h3>
&lt;p>生产者拦截器既可以用来在消息发送前做一些准备工作，比如按照某个规则过滤不符合要求的消息、修改消息的内容等，也可以用来在发送回调逻辑前做一些定制化的需求，比如统计类工作。&lt;/p>
&lt;h2 id="2-2-原理分析">2.2 原理分析&lt;/h2>
&lt;h3 id="2-2-1-整体架构">2.2.1 整体架构&lt;/h3>
&lt;h3 id="2-2-2-元数据的更新">2.2.2 元数据的更新&lt;/h3>
&lt;h2 id="2-3-重要的生产者参数">2.3 重要的生产者参数&lt;/h2>
&lt;p>1、acks&lt;/p>
&lt;p>2、max.request.size 生产者客户端能发送的消息的最大值，默认1MB&lt;/p>
&lt;p>3、retries（重试次数）和retry.backoff.ms（重试时间间隔）&lt;/p>
&lt;p>4、compression.type（消息的压缩方式）&lt;/p>
&lt;p>5、connections.max.idle.ms（多久关闭限制的链接）&lt;/p>
&lt;p>6、linger.ms&lt;/p>
&lt;p>7、receive.buffer.bytes（Socket接收消息缓冲区SO_RECBUF的大小）&lt;/p>
&lt;p>8、send.buffer.bytes（Socket发送消息缓冲区SO_RECBUF的大小）&lt;/p>
&lt;p>9、request.timeout.ms（Producer等待请求响应的最长时间）&lt;/p>
&lt;h2 id="2-4-总结">2.4 总结&lt;/h2>
&lt;p>KafkaProducer是线程安全的，可以在多线程的环境中复用，而对于下一章的消费者客户端KafkaConsumer而言，是非线程安全的，因为它具备了状态。&lt;/p>
&lt;h1 id="03-消费者">03 消费者&lt;/h1>
&lt;h2 id="3-1-消费者与消费组">3.1 消费者与消费组&lt;/h2>
&lt;p>对于消息中间件而言，一般有两种消息投递模式：点对点（P2P，Point-to-Point）模式和发布/订阅（Pub/Sub）模式。点对点模式是基于队列的，消息生产者发送消息到队列，消息消费者从队列中接收消息。发布订阅模式定义了如何向一个内容节点发布和订阅消息，这个内容节点成为主体（Topic），主体可以认为是消息传递的中介，消息发布者将消息发布到某个主题，而消息订阅者从主题中订阅消息。主题使得消息的订阅者和发布者互相保持独立，不需要进行接触即可保证消息的传递，发布/订阅模式在消息的一对多广播时采用。Kafka同时支持两种消息投递模式，而这正是得益于消费者与消费者模式的契合：&lt;/p>
&lt;ul>
&lt;li>如果所有的消费者都隶属于同一个消费组，那么所有的消息都会被均衡地投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于点对点模式的应用。&lt;/li>
&lt;li>如果所有的消费者都隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息会被所有的消费者处理，这就相当于发布/订阅模式的应用。&lt;/li>
&lt;/ul>
&lt;h2 id="3-2-客户端开发">3.2 客户端开发&lt;/h2>
&lt;p>一个正常的消费逻辑需要具备以下几个步骤：&lt;/p>
&lt;p>1、配置消费者客户端参数及创建相应的消费者实例&lt;/p>
&lt;p>2、订阅主题&lt;/p>
&lt;p>3、拉取消息并消费&lt;/p>
&lt;p>4、提交消费位移&lt;/p>
&lt;p>5、关闭消费者实例&lt;/p>
&lt;h3 id="3-2-1-必要的参数配置">3.2.1 必要的参数配置&lt;/h3>
&lt;ul>
&lt;li>bootstrap.serviers：释义与生产者客户端KafkaProducer中的相同，指定连接Kafka集群所需的broker地址清单，形式为host1:port1,host2:post2，可以设置一个或多个&lt;/li>
&lt;li>group.id：消费者隶属的消费组的名称，默认值为“”。为空会抛出异常。一般会设置成具有一定的业务意义的名称。&lt;/li>
&lt;li>key.deserializer和value.deserializer：与生产者客户端KafkaProducer中的key.serializer和value.serializer参数对应。必须填写全限定名如org.apache.kafka.common.serialization.StringDeserializer。&lt;/li>
&lt;li>client.id：设定KafkaConsumer对应的客户端id，默认值也为&amp;quot;&amp;quot;。不设置会自动生成一个非空字符串，如“consumer-1”“consumer-2”。&lt;/li>
&lt;/ul>
&lt;h3 id="3-2-2-订阅主题与分区">3.2.2 订阅主题与分区&lt;/h3>
&lt;h3 id="3-2-3-反序列化">3.2.3 反序列化&lt;/h3>
&lt;h3 id="3-2-4-消息消费">3.2.4 消息消费&lt;/h3>
&lt;p>Kafka中的消费是基于拉模式的。消息的消费一般有两种模式：推模式和拉模式。&lt;/p>
&lt;p>Kafka中的消息消费是一个不断轮询的过程，消费者索要做的就是重复地调用poll()方法，而该方法返回的所订阅的主题（分区）上的一组消息。&lt;/p>
&lt;h3 id="3-2-5-位移提交">3.2.5 位移提交&lt;/h3>
&lt;ul>
&lt;li>偏移量：消息在分区中的位置（存储层面）&lt;/li>
&lt;li>位移（消费位移）：消费者消费到的位置（消费层面）&lt;/li>
&lt;/ul>
&lt;p>位移提交（难点），采用自动提交，带来的问题：重复消费、消息丢失。&lt;/p>
&lt;h3 id="3-2-6-控制或关闭消费">3.2.6 控制或关闭消费&lt;/h3>
&lt;h3 id="3-2-7-指定位移消费">3.2.7 指定位移消费&lt;/h3>
&lt;p>当消费者找不到消费位移时（如新的消费组），就会根据消费者客户端参数auto.offset.reset的配置来决定，默认值为”latest”，表示从分区末尾开始消费消息。如果&lt;/p>
&lt;p>参数配置为&amp;quot;earliest&amp;quot;，那么消费者会从起始处开始消费。&lt;/p>
&lt;h3 id="3-2-8-再均衡">3.2.8 再均衡&lt;/h3>
&lt;p>再均衡是指分区的所属权从一个消费者转移到另一消费者的行为，它为消费组具备高可用性和伸缩性提供保障，使我们可以既方便又安全地删除消费组内的消费者或往消费组内添加消费者。再均衡期间，消费者无法读取消息。&lt;/p>
&lt;p>“重复消费”问题：再均衡之前消费了一次，之后又消费了一次。一般情况下应避免不必要的再均衡的发生。&lt;/p>
&lt;p>再均衡监听器用来设定发生再均衡动作前后的一些准备或收尾的动作。&lt;/p>
&lt;h3 id="3-2-9-消费者拦截器">3.2.9 消费者拦截器&lt;/h3>
&lt;h3 id="3-2-10-多线程实现">3.2.10 多线程实现&lt;/h3>
&lt;p>KafkaProducer是线程安全的，但KafaConsumer是非线程安全的。KafaConsumer中定义了一个acquire()方法，用来检测当前是否只有一个线程在操作，若有其它线程正在操作则会抛出异常。&lt;/p>
&lt;p>方块大小和滑动窗口的大小同时决定了消费线程的并发数：一个方格对应一个消费线程，对于窗口大小固定的情况，方格越小并行度越高；对于方格大小固定的情况，窗口越大并行度越高。&lt;/p>
&lt;h3 id="3-2-11-重要的消费者参数">3.2.11 重要的消费者参数&lt;/h3>
&lt;p>1、fetch.min.bytes：配置Consumer在一次拉取请求（调用poll()方法）中能从Kafka中拉取的最小数据量，默认值为1(B)。&lt;/p>
&lt;p>2、fetch.max.bytes：与上个参数相反，默认值为52428800(B)，也就是50MB。&lt;/p>
&lt;p>3、fetch.max.wait.ms：&lt;/p>
&lt;p>…&lt;/p>
&lt;h1 id="04-主题与分区">04 主题与分区&lt;/h1>
&lt;h2 id="4-1-主题的管理">4.1 主题的管理&lt;/h2>
&lt;h3 id="4-1-1-创建主题">4.1.1 创建主题&lt;/h3>
&lt;h3 id="4-1-2-分区副本的分配">4.1.2 分区副本的分配&lt;/h3>
&lt;h3 id="4-1-3-查看主题">4.1.3 查看主题&lt;/h3>
&lt;h3 id="4-1-4-修改主题">4.1.4 修改主题&lt;/h3>
&lt;p>问：为什么不支持减少分区？&lt;/p>
&lt;p>答：按照kafka现有的代码逻辑，此功能完全可以实现，不过也会使代码的复杂度急剧增大。实现此功能需要考虑的因素很多，比如删除的分区中的消息该如何处理？如果随着分区一起消失则消息的可靠性得不到保障；如果需要保留则又需要考虑如何保留。直接存储到现有分区的尾部，消息的时间戳就不会递增，如此对于Spark、Flink这类需要消息时间戳（事件时间）的组件将会受到影响；如果分散插入现有的分区，那么在消息量很大的时候，内部的数据复制会占用很大的资源，而且在复制期间，此主题的可用性又如何得到保障？与此同时，顺序性问题、事务性问题，以及分区和副本的状态机切换问题都是不得不面对的。反观这个功能的受益点确是很低的，如果真的需要实现此类功能，则完全可以重新创建一个分区数较小的主题，然后将现有主题中的消息按照既定的逻辑复制过去即可。&lt;/p>
&lt;h3 id="4-1-5-配置管理">4.1.5 配置管理&lt;/h3>
&lt;p>kafka-configs.sh脚本专门用来对配置进行操作。&lt;/p>
&lt;h3 id="4-1-6-主题端参数">4.1.6 主题端参数&lt;/h3>
&lt;h3 id="4-1-7-删除主题">4.1.7 删除主题&lt;/h3>
&lt;h2 id="4-2-初识kafkaadminclient">4.2 初识KafkaAdminClient&lt;/h2>
&lt;p>一般使用kafka-topic.sh脚本来管理主题，但有时候希望将主题管理类功能集成到公司内部的系统中，打造集管理、监控、运维、告警为一体的生态平台，那么需要以程序调用API的方式去实现。&lt;/p>
&lt;h3 id="4-2-1-基本使用">4.2.1 基本使用&lt;/h3>
&lt;h3 id="4-2-2-主题合法性验证">4.2.2 主题合法性验证&lt;/h3>
&lt;h2 id="4-3-分区的管理">4.3 分区的管理&lt;/h2>
&lt;h3 id="4-3-1-优先副本的选举">4.3.1 优先副本的选举&lt;/h3>
&lt;h3 id="4-3-2-分区重分配">4.3.2 分区重分配&lt;/h3>
&lt;h3 id="4-3-3-复制限流">4.3.3 复制限流&lt;/h3>
&lt;h3 id="4-3-4-修改副本因子">4.3.4 修改副本因子&lt;/h3>
&lt;h2 id="4-4-如何选择合适的分区数">4.4 如何选择合适的分区数&lt;/h2>
&lt;p>根据实际的业务场景、软件条件、硬件条件、负载情况等来做具体的考量。&lt;/p>
&lt;h3 id="4-4-1-性能测试工具">4.4.1 性能测试工具&lt;/h3>
&lt;p>Kafka本身提供的用于生产者性能测试的kafka-producer-perf-test.sh和用于消费者性能测试的kafka-consumer-perf-test.sh。&lt;/p>
&lt;h3 id="4-4-2-分区数越多吞吐量就越高吗">4.4.2 分区数越多吞吐量就越高吗&lt;/h3>
&lt;p>消息中间件的性能一般是指吞吐量（广义来说还包括延迟）。抛开硬件资源的影响，消息写入的吞吐量还会受到消息大小、消息压缩方式、消息发送方式（同步/异步）、消息确认类型（acks）、副本因子等参数的影响，消息消费的吞吐量还会受到应用逻辑处理速度的影响。&lt;/p>
&lt;p>一般情况下，根据预估的吞吐量及是否与key相关的规则来设定分区数即可，后期可以通过增加分区数、增加broker或分区重分配等手段来进行改进。如果一定要一个准则，则建议将分区数设定为集群中broker的倍数，即假定集群中有3个broker节点，可以设定分区数为3、6、9等，至于倍数的选定可以参考预估的吞吐量。不过，如果集群中的broker节点数有很多，比如大几十或上百、上千，那么这种准则也不太适用，在选定分区数时进一步可以引入基架等参考因素。&lt;/p>
&lt;h1 id="05-日志存储">05 日志存储&lt;/h1>
&lt;h2 id="5-1-文件目录布局">5.1 文件目录布局&lt;/h2>
&lt;p>不考虑多副本的情况，一个分区对应一个日志（Log）。为了防止Log过大，Kafka又引入了日志分段（LogSegment）的概念，将Log切分为多个LogSegment，相当于一个巨型文件被平均分配为多个相对较小的文件，这样也便于消息的维护和清理。事实上，Log和LogSegment也不是纯粹物理意义上的概念，Log在物理上只以文件夹的形式存储，而每个LogSegment对应于磁盘上的一个日志文件和两个索引文件，以及可能的其他文件（比如以“.txnindex”为后缀的事务索引文件）。&lt;/p>
&lt;p>向Log中追加消息时是顺序写入的，只有最后一个LogSegment才能执行写入操作。在此之前所有的LogSegment都不能写入数据。为了方便描述，我们将最后一个LogSegment称为“activeSegment”，即表示当前活跃的的日志分段。&lt;/p>
&lt;p>为了便于消息的检索，每个LogSegment中的日志文件（以“.log”为文件后缀）都有对应的两个索引文件：偏移量索引文件（以“.index”为文件后缀）和时间戳索引文件（以“.timeindex”为文件后缀）。每个LogSegment都有一个基准偏移量baseOffset，用来表示当前LogSegment中第一条消息的offerset。偏移量是一个64位的长整型数，日志文件和两个索引文件都是根据基准偏移量（baseOffset）命名的，名称固定为20位数字，没有达到的位数则用0填充。比如第一个LogSegment的基准偏移量为0，对应的日志文件为00000000000000000000.log。&lt;/p>
&lt;h2 id="5-2-日志格式的演变">5.2 日志格式的演变&lt;/h2>
&lt;p>Kafka的消息格式也经历了3个版本：v0版本、v1版本和v2版本。&lt;/p>
&lt;h3 id="5-2-1-v0版本">5.2.1 v0版本&lt;/h3>
&lt;p>Kafka消息格式的第一个版本通常称为v0版本，在Kafka 0.10.0之前都采用的这个消息格式（在0.8.x版本之前还是用过一个更古老的消息格式，忽略）&lt;/p>
&lt;h4 id="5-2-2-v1版本">5.2.2 v1版本&lt;/h4>
&lt;p>Kafka从0.10.0版本开始到0.11.0版本之前所使用的消息格式版本为v1，比v0版本就多了一个timestamp字段，表示消息的时间戳。&lt;/p>
&lt;h3 id="5-2-3-消息压缩">5.2.3 消息压缩&lt;/h3>
&lt;p>常见的压缩算法是数据量越大压缩效果越好，一条消息通常不会太大，这就导致压缩效果并不是太好。而Kafka实现的压缩方式是将多条消息一起进行压缩，这样可以保证较好的压缩效果。&lt;/p>
&lt;h3 id="5-2-4-变长字段">5.2.4 变长字段&lt;/h3>
&lt;p>Kafka从0.11.0版本开始所使用的的消息格式版本为v2，这个版本的消息相比v0和v1的版本而言改动很大，同时还参考了Protocol Buffer而引入了变长整型（Varints）和ZigZag编码。&lt;/p>
&lt;p>Varints是使用一个或多个字节来序列化整数的一种方法。数值越小，其占用的字节数就越少。Varints中的每个字节都有一个位于最高位的msb位（most significant bit），除最后一个字节外，其余msb位都设置为1，最后一个字节的msb位为0。&lt;/p>
&lt;h3 id="5-3-日志索引">5.3 日志索引&lt;/h3>
&lt;p>偏移量索引文件用来建立消息偏移量（offset）到物理地址之间的映射关系，方便快速定位消息所在的物理文件位置；时间戳索引文件则根据指定的时间戳（timestamp）来查找对应的偏移量信息。&lt;/p>
&lt;p>Kafka中的索引文件以稀疏索引（sparse index）的方式构造消息的索引，它并不保证每个消息在索引文件中都有对应的索引项。&lt;/p>
&lt;p>稀疏索引通过MappedByteBuffer将索引文件映射到内存中，以加快索引的查询速度。偏移量索引文件中的偏移量是单调递增的，查询指定偏移量时，使用二分查找法来快速定位偏移量的位置，如果指定的偏移量不在索引文件中，则会返回小于指定偏移量的最大偏移量。时间戳索引文件中的时间戳也保持严格的单调递增，查询指定时间戳时，也根据二分查找法来查找不大于该时间戳的最大偏移量，至于要找到对应的物理文件位置还需要根据偏移量索引文件来进行再次定位。稀疏索引的方式是在磁盘空间、内存空间、查找时间等多方面之间的一个折中。&lt;/p>
&lt;h3 id="5-3-1-偏移量索引">5.3.1 偏移量索引&lt;/h3>
&lt;p>偏移量索引项分为两个部分：&lt;/p>
&lt;p>（1）relativeOffset：相对偏移量&lt;/p>
&lt;p>（2）position：物理地址&lt;/p>
&lt;h3 id="5-3-2-时间戳索引">5.3.2 时间戳索引&lt;/h3>
&lt;h2 id="5-4-日志清理">5.4 日志清理&lt;/h2>
&lt;p>Kafka提供了两种日志清理策略：&lt;/p>
&lt;p>（1）日志删除（Log Retention）&lt;/p>
&lt;p>（2）日志压缩（Log Compaction）&lt;/p>
&lt;h3 id="5-4-1-日志删除">5.4.1 日志删除&lt;/h3>
&lt;p>日志分段的保留策略：&lt;/p>
&lt;p>（1）基于时间&lt;/p>
&lt;p>（2）基于日志大小&lt;/p>
&lt;p>（3）基于日志起始偏移量&lt;/p>
&lt;h3 id="5-4-2-日志压缩">5.4.2 日志压缩&lt;/h3>
&lt;h2 id="5-5-磁盘存储">5.5 磁盘存储&lt;/h2>
&lt;h3 id="5-5-1-页缓存">5.5.1 页缓存&lt;/h3>
&lt;h3 id="5-5-2-磁盘i-o流程">5.5.2 磁盘I/O流程&lt;/h3>
&lt;h3 id="5-5-3-零拷贝">5.5.3 零拷贝&lt;/h3>
&lt;p>所谓的零拷贝是指将数据直接从磁盘文件复制到网卡设备中，而不需要经由应用程序之手。&lt;/p>
&lt;h2 id="5-6-总结">5.6 总结&lt;/h2>
&lt;h1 id="06-深入服务端">06 深入服务端&lt;/h1>
&lt;p>6.1 协议设计&lt;/p>
&lt;p>6.2 时间轮&lt;/p>
&lt;p>6.3 延时操作&lt;/p>
&lt;p>6.4 控制器&lt;/p>
&lt;p>6.4.1 控制器的选举及异常恢复&lt;/p>
&lt;p>6.4.2 优雅关闭&lt;/p>
&lt;p>6.4.3 分区leader的选举&lt;/p>
&lt;p>6.5 参数解密&lt;/p>
&lt;p>6.5.1 broker.id&lt;/p>
&lt;p>6.5.2 bootstrap.servers&lt;/p>
&lt;p>6.5.3 服务端参数列表&lt;/p>
&lt;p>6.6 总结&lt;/p>
&lt;h1 id="07-深入客户端">07 深入客户端&lt;/h1>
&lt;p>7.1 分区分配策略&lt;/p>
&lt;p>7.1.1 RangeAssignor分配策略&lt;/p>
&lt;p>7.1.2 RoundRobinAssignor分配策略&lt;/p>
&lt;p>7.1.3 StickyAssignor分配策略&lt;/p>
&lt;p>7.1.4 自定义分区分配策略&lt;/p>
&lt;p>7.2 消费者协调器和组协调器&lt;/p>
&lt;p>7.2.1 旧版消费者客户端的问题&lt;/p>
&lt;p>7.2.2 再均衡的原理&lt;/p>
&lt;p>7.3 __consumer_offsets剖析&lt;/p>
&lt;p>7.4 事务&lt;/p>
&lt;p>7.4.1 消息传输保障&lt;/p>
&lt;p>7.4.2 幂等&lt;/p>
&lt;p>7.4.3 事务&lt;/p>
&lt;p>7.5 总结&lt;/p>
&lt;h1 id="08-可靠性探究">08 可靠性探究&lt;/h1>
&lt;p>8.1 副本剖析&lt;/p>
&lt;p>8.1.1 失效副本&lt;/p>
&lt;p>8.1.2 ISR的伸缩&lt;/p>
&lt;p>8.1.3 LEO与HW&lt;/p>
&lt;p>8.1.4 Leader Epoch的介入&lt;/p>
&lt;p>8.1.5 为什么不支持读写分离&lt;/p>
&lt;p>（1）数据一致性问题&lt;/p>
&lt;p>（2）延时问题&lt;/p>
&lt;p>8.2 日志同步机制&lt;/p>
&lt;p>8.3 可靠性分析&lt;/p>
&lt;p>8.4 总结&lt;/p>
&lt;h1 id="09-kafka应用">09 Kafka应用&lt;/h1>
&lt;h2 id="9-1-命令行工具">9.1 命令行工具&lt;/h2>
&lt;h3 id="9-1-1-消费组管理">9.1.1 消费组管理&lt;/h3>
&lt;h3 id="9-1-2-消费位移管理">9.1.2 消费位移管理&lt;/h3>
&lt;h3 id="9-1-3-手动删除消息">9.1.3 手动删除消息&lt;/h3>
&lt;h2 id="9-2-kafka-connect">9.2 kafka Connect&lt;/h2>
&lt;p>Kafka Connect是一个工具，它为在Kafka和外部数据存储系统之间移动数据提供了一种可靠的且可伸缩的实现方式。&lt;/p>
&lt;p>Kafka Connect有两个核心概念：Source和Sink。Source负责导入数据到Kafka，Sink负责从Kafka导出数据，它们都被称为Connector（连接器）。&lt;/p>
&lt;p>两个重要概念：Task和Worker。Task是Kafka Connect数据模型的主角，每一个Connector都会协调一系列的Task去执行任务，Connector可以把一项工作分割成许多Task，然后把Task分发到各个Worker进程中去执行（分布式模式下），Task不保存自己的状态信息，而是交给特定的Kafka主题去保存。Connector和Task都是逻辑工作单位，必须安排在进程中执行，而在Kafka Connect中，这些进程就是Worker。&lt;/p>
&lt;p>Kafka Connect提供了以下特性：&lt;/p>
&lt;ul>
&lt;li>通用性：规范化其他数据系统与Kafka的继承，简化了连接器的开发、部署和管理。&lt;/li>
&lt;li>支持独立模式（standalone）和分布式模式（distributed）。&lt;/li>
&lt;li>REST接口：使用REST API提交和管理Connector。&lt;/li>
&lt;li>自动位移管理：自动管理位移提交，不需要开发人员干预，降低了开发成本。&lt;/li>
&lt;li>分布式和可扩展性：Kafka Connect基于现有的组管理协议来实现扩展Kafka Connect集群。&lt;/li>
&lt;li>流式计算/批处理的集成。&lt;/li>
&lt;/ul>
&lt;h3 id="9-2-1-独立模式">9.2.1 独立模式&lt;/h3>
&lt;p>Kafka中的connect-standalone.sh脚本用来实现以独立的模式运行Kafka Connect。&lt;/p>
&lt;h3 id="9-2-2-rest-api">9.2.2 REST API&lt;/h3>
&lt;p>默认端口号为8083，可以通过Worker进程的配置文件中的rest.port参数来修改端口号。&lt;/p>
&lt;h3 id="9-2-3-分布式模式">9.2.3 分布式模式&lt;/h3>
&lt;p>以分布式模式启动的连接器并不支持在启动时通过加载连接器配置文件来创建一个连接器，只能通过访问REST API来创建连接器。&lt;/p>
&lt;h3 id="9-4-kafka-streams">9.4 Kafka Streams&lt;/h3>
&lt;p>Kafka实现了高吞吐、高可用和低延时的消息传输能力，这让它成为流式处理系统中完美的数据来源。目前通用的一些流式处理框架如Apache Spark、Apache Flink、Apache Storm等都可以将Kafka作为可靠的数据来源。但遗憾的是，在0.10.x版本之前，Kafka还并不具备任何数据处理的能力，但在此之后，Kafka Streams应运而生。&lt;/p>
&lt;p>Kafka Streams直接解决了流式处理中的很多问题&lt;/p>
&lt;ul>
&lt;li>毫秒级延迟的逐个事件处理&lt;/li>
&lt;li>有状态的处理，包括连接（join）和聚合类操作&lt;/li>
&lt;li>提供了必要的流处理原语，包括高级流处理DSL和低级处理器API。高级流处理DSL提供了常用流处理变换操作，低级处理器API支持客户端自定义处理器并与状态仓库交互&lt;/li>
&lt;li>使用类似DataFlow的模型对无序数据进行窗口化处理&lt;/li>
&lt;li>具有快速故障切换的分布式处理和容错能力&lt;/li>
&lt;li>无停机滚动部署&lt;/li>
&lt;/ul>
&lt;h2 id="9-5-总结">9.5 总结&lt;/h2>
&lt;h1 id="10-kafka监控">10 Kafka监控&lt;/h1>
&lt;p>以Kafka manager为例，它提供的监控功能也是相对比较完善的，在实际应用中具有很高的使用价值。但有一个遗憾就是其难以和公司内部系统平台关联，对于业务资源的使用情况、相应的预防及告警的联动无法顺利贯通。 &lt;/p>
&lt;h2 id="10-1-监控数据的来源">10.1 监控数据的来源&lt;/h2>
&lt;h3 id="10-1-1-oneminuterate">10.1.1 OneMinuteRate&lt;/h3>
&lt;h3 id="10-1-2-获取监控指标">10.1.2 获取监控指标&lt;/h3>
&lt;h2 id="10-2-消费滞后-lag">10.2 消费滞后（Lag）&lt;/h2>
&lt;p>消息堆积是消息中间件的一大特色，消息中间件的流量削峰、冗余存储等功能正是得益于消息中间件的消息堆积能力。这是一把双刃剑。有些中间件如RabbitMQ在发生消息堆积时还会影响自身的性能。对Kafka而言，虽然消息堆积不会给其自身性能带来太大的困扰，但难免会影响上下游的业务，堆积过多有可能造成磁盘爆满，或者触发日志清楚操作而造成消息丢失的情况。&lt;/p>
&lt;p>（1）普通情况：&lt;/p>
&lt;p>Lag = HW - ConsumerOffset（消费位移）&lt;/p>
&lt;p>（2）引入事务：&lt;/p>
&lt;p>1）消费者客户端的isolation.level参数配置为read_uncommitted（默认），Lag计算方式不受影响。&lt;/p>
&lt;p>2）上述参数配置为read_commmitted，引入LSO来计算。LSO是LastStableOffset的缩写。&lt;/p>
&lt;p>对未完成的事务而言，LSO的值等于事务中第一条消息的位置（firstUnstableOffset）；&lt;/p>
&lt;p>Lag = LSO - ConsumerOffset&lt;/p>
&lt;p>对已完成的事务而言，它的值同HW相同，结论：LSO&amp;lt;=HW&amp;lt;=LEO。&lt;/p>
&lt;h2 id="10-3-同步失效分区">10.3 同步失效分区&lt;/h2>
&lt;p>消费Lag是Kafka的普通使用者特别关心的一项指标，而同步失效分区（under-replicated）的多少是Kafka运维人员非常关心的一项指标。8.1.1节中的概念：处于同步失效或功能失效（比如处于非活跃状态）的副本统称为失效副本。而包含失效副本的分区也就称为同步失效分区。&lt;/p>
&lt;p>Kafka本身提供了一个相关的指标来表征失效分区的个数，即UnderReplicatedPartitions，可以通过JMX访问来获取其值：&lt;/p>
&lt;p>kafka.server:type=ReplicaManager,name=UnderRelicatedPartitions&lt;/p>
&lt;p>注意：如果Kafka集群正在做分区重分配（参考4.3.2节），该值也大于0.&lt;/p>
&lt;p>如果集群中有多个broker的UnderReplicatedPartitions保持一个大于0的稳定值，则一般暗示集群中有broker已经处于下线状态。该情况下，这个broker中的分区个数与集群中的所有UnderRepliatedPartitions（处于下线的broker是不会上报任何指标值得）之和是相等的。通常这类问题是由于机器硬件原因引起的，但也有可能是由于操作系统或JVM引起的，可以往这个方向继续做进一步的深入调查。&lt;/p>
&lt;p>如果集群中存在broker的UnderReplicatedPartitions频繁变动，或者处于一个稳定的大于0的值（这里特指没有broker下线的情况）时，一般暗示集群出现了性能问题。确定某个broker，然后针对单一的broker做专项调查，比如操作系统、GC、网络状态或磁盘状态（如iowait、ioutil等指标）。&lt;/p>
&lt;p>如果多个broker中都出现了under-replicated分区，则一般是整个集群的问题，但也有可能是单个broker出现了问题。对于后者，如果单个broker在消息同步方面出了问题，那么其上的follower副本就无法及时有效地与其他broker上的leader副本进行同步，就出现了多个broker都存在under-replicated分区的现象。&lt;/p>
&lt;p>集群层面的问题一般也就是两个方面：资源瓶颈和负载不均衡。资源瓶颈指的是broker在某硬件资源的使用上遇到了瓶颈，比如网络、CPU、I/O等层面。就以I/O而论，Kafka中的消息都是存盘的，生产者线程将消息写入leader副本的性能和I/O有着直接的关联，follower副本的同步线程及消费者的消费线程又要通过I/O从磁盘中拉取消息，如果I/O层面出现了瓶颈，那么势必影响全局的走向，与此同时消息的流入/流出又都需要和网络打交道。建议硬件层面的指标可以关注CPU的使用率、网络流入/流出速度、磁盘的读/写速度、iowait、ioutil等，也可以适当地关注下文件句柄数、Socket句柄数及内存等方面。&lt;/p>
&lt;h2 id="10-4-监控指标说明">10.4 监控指标说明&lt;/h2>
&lt;p>Kafka自身提供的JMX监控指标已经超过了500个，这里挑选部分重要及常用指标进行说明。&lt;/p>
&lt;h2 id="10-5-监控模块">10.5 监控模块&lt;/h2>
&lt;p>Kafka的监控架构主要分为数据采集、数据存储和数据展示这3个部分。数据采集主要指从各个数据源采集监控数据并做一些必要的运算，然后发送给数据存储模块进行存储。数据源可以是Kafka配套的Zookeeper、Kafka自身提供的内部运行指标（通过JMX获取）、Kafka内部的一些数据（比如__consumer_ooffset中存储的信息，通过Kafka自定义协议获取）、Falcon/Zabbix等第三方工具（或者其他类似的工具、主要用来监控集群的硬件指标）。&lt;/p>
&lt;p>数据存储可以采用OpenTSDB之类的基于时间序列的数据库，方便做一些聚合计算，也可以附加采用Redis、MySQL等存储特定数据。&lt;/p>
&lt;h2 id="10-6-总结">10.6 总结&lt;/h2>
&lt;h1 id="11-高级应用">11 高级应用&lt;/h1>
&lt;p>高级应用类的需求，比如消费回溯，可以通过原生Kafka提供的KafkaConsumer.seek()方法来实现，然而类似延迟队列、消息轨迹等应用需求在原生Kafka中就没有提供了。本章讲述如何扩展类高级应用。 &lt;/p>
&lt;p>11.1 过期时间（TTL）&lt;/p>
&lt;p>11.2 延时队列&lt;/p>
&lt;p>11.3 死信队列和重试队列&lt;/p>
&lt;p>11.4 消息路由&lt;/p>
&lt;p>11.5 消息轨迹&lt;/p>
&lt;p>11.6 消息审计&lt;/p>
&lt;p>11.7 消息代理&lt;/p>
&lt;p>11.7.1 快速入门&lt;/p>
&lt;p>11.7.2 REST API介绍及示例&lt;/p>
&lt;p>11.7.3 服务端配置及部署&lt;/p>
&lt;p>11.7.4 应用思考&lt;/p>
&lt;p>11.8 消息中间件选型&lt;/p>
&lt;p>11.8.1 各类消息中间件简述&lt;/p>
&lt;p>11.8.2 选型要点概述&lt;/p>
&lt;p>11.8.3 消息中间件选型误区探讨&lt;/p>
&lt;p>11.9 总结&lt;/p>
&lt;h1 id="12-kafka与spark的集成">12 Kafka与Spark的集成&lt;/h1>
&lt;p>12.1 Spark的安装及简单应用&lt;/p>
&lt;p>12.2 Spark编程模型&lt;/p>
&lt;p>12.3 Spark的运行结构&lt;/p>
&lt;p>12.4 Spark Streaming简介&lt;/p>
&lt;p>12.5 Kafka与Spark Streaming的整合&lt;/p>
&lt;p>12.6 Spark SQL&lt;/p>
&lt;p>12.7 Structured Streaming&lt;/p>
&lt;p>12.8 Kafka与Structured Streaming的整合&lt;/p>
&lt;p>12.9 总结&lt;/p>
&lt;h1 id="附录a-kafka源码环境搭建">附录A Kafka源码环境搭建&lt;/h1></description></item><item><title>Docs: Pulsar</title><link>/docs/43.MQ/Pulsar/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/43.MQ/Pulsar/</guid><description>
&lt;h1 id="背景">背景&lt;/h1>
&lt;h2 id="pulsar介绍">Pulsar介绍&lt;/h2>
&lt;p>Apache Pulsar 是一个云原生、分布式的流式处理和消息队列的平台。&lt;/p>
&lt;p>关键特性：&lt;/p>
&lt;ul>
&lt;li>云原生架构（计算与存储分离），无缝支持跨集群复制&lt;/li>
&lt;li>比kafka更高的吞吐量和低延迟&lt;/li>
&lt;li>无缝支持上百万个topics支持多种消息订阅模式 (exclusive &amp;amp; shared &amp;amp; failover)&lt;/li>
&lt;li>通过持久化存储BookKeeper保障消息的传递&lt;/li>
&lt;li>轻量级Serverless计算框架Pulsar Functions提供了流式数据处理能力。&lt;/li>
&lt;li>提供分层存储能力，释放BookKeeper的空间：将老数据or长期不用的数据放到AWS S3等&lt;/li>
&lt;/ul>
&lt;h1 id="传统mq问题">传统MQ问题&lt;/h1>
&lt;p>以 Kafka 举例，Kafka 把 broker 和 partition 的数据存储牢牢绑定在一起，会产生很多问题。&lt;/p>
&lt;p>&lt;img src="../imgs/20230114_pulsar_1.png" alt="20230114_pulsar_1.png">&lt;/p>
&lt;h2 id="数据全量复制">数据全量复制&lt;/h2>
&lt;p>Kafka 的很多操作都涉及 partition 数据的全量复制。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>扩容broker
假设有 broker1, broker2 两个节点，分别负责若干个 partition，如果新加入一个 broker3 节点分摊 broker1 的部分负载，那么 broker1 得分出一些 partition 给到 broker3。必须复制 partition 的全量数据之后，broker3 才能提供服务。不仅消耗 IO 以及网络资源，且如果复制数据的速度小于 partition 的写入速度，那就无法完成复制。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>增加follower副本
新增 follower 副本必须要跟 leader 副本同步全量数据。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>partition迁移
如果某些 partition 中的数据特别多（数据倾斜），对应 broker 的磁盘可能很快被写满，会涉及到 partition 的迁移，数据复制无法避免。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>虽然 Kafka 提供了现成的脚本可以完成这些事情，但实际面临的问题较多，操作也较复杂，数据迁移也是一件耗时耗力的事，远远做不到集群级别的自动的平滑操作。&lt;/p>
&lt;h2 id="依赖page-cache">依赖Page Cache&lt;/h2>
&lt;p>Page Cache 实际上就是文件的读写缓存，Linux 文件系统会利用该机制优化性能，写入数据时 Linux 返回成功，实际上数据并没有真正写入磁盘中，而是写到了 Page Cache 缓存中，等后续刷新写入到磁盘中。当出现断电等系统故障时，如果缓存中数据没有写入磁盘中，那么会出现数据丢失的情况。&lt;/p>
&lt;p>Kafka 底层完全依赖 Page Cache，没有要求 Linux 强制刷新磁盘，对于一些强一致的需求场景是不可接受的，如金融、电商等。&lt;/p>
&lt;p>另外 Page Cache 也是有可能出现性能问题的。消费者消费数据可以分为以下两种情况：&lt;/p>
&lt;ul>
&lt;li>追尾读（Tailing Reads）
定义：就是消费者的消费速度很快，生产者生产消息，消费者立刻能够消费。&lt;/li>
&lt;/ul>
&lt;p>broker处理过程：生产者生产消息，broker 写入到 Page Cache 写缓存，消费者立刻来读取消息，这时 broker 可以快速从 Page Cache 读取消息发送给消费者。&lt;/p>
&lt;ul>
&lt;li>追赶读（Catch-up Reads）
定义：消费者的消费速度很慢，生产者生产了很多新消息，但消费者还在读取比较旧的消息。&lt;/li>
&lt;/ul>
&lt;p>broker处理过程：Page Cache 缓存里没有消费者想读取的旧消息，broker 必须从磁盘中读取数据并存储在 Page Cache 读缓存中。这样读写操作都依赖 Page Cache，就会导致读写操作会互相影响，对一个 partition 的大量读可能影响写性能，大量写也可能会影响读性能，并且读写缓存会互相争抢内存资源，可能会造成 IO 性能问题。&lt;/p>
&lt;h1 id="架构设计">架构设计&lt;/h1>
&lt;p>基于传统 MQ 的一些问题，Pulsar 在系统架构上做了一些重新设计，如计算存储分离、读写分离。&lt;/p>
&lt;h2 id="分层架构">分层架构&lt;/h2>
&lt;h3 id="broker无状态层">Broker无状态层&lt;/h3>
&lt;p>与kafka不同，Pulsar Broker不存储实际的数据，而是将消息存储在 BookKeeper 中，仅仅拥有 Topic/Partitions 的代理权。屏蔽了 message 复杂的读写流程，保证了数据一致性和负载均衡。meta 信息是存储在 zookeeper 中，消息存储到 BookKeeper 中。&lt;/p>
&lt;h3 id="bookkeeper存储层">BookKeeper存储层&lt;/h3>
&lt;p>BookKeeper 是一个分布式的预写日志（WAL）系统，Pulsar 使用 Apache BookKeeper 作为持久化存储。&lt;/p>
&lt;p>主要特性有：&lt;/p>
&lt;ul>
&lt;li>支持创建多个独立的 ledgers（Fragment/Segment）随着时间的推移，底层数据以 Ledger形式存储，Pulsar会为Topic创建多个 ledgers。&lt;/li>
&lt;li>为按条目复制的顺序数据提供了非常高效的存储。&lt;/li>
&lt;li>保证了多系统挂掉时ledgers的读取一致性。&lt;/li>
&lt;li>提供不同的Bookies（BookKeeper实例）均匀的IO分布的特性。&lt;/li>
&lt;li>容量和吞吐量都能水平扩展。并且容量可以通过在集群内添加更多的Bookies立刻提升。&lt;/li>
&lt;li>被设计成可以承载数千的并发读写的ledgers。 使用多个磁盘设备，一个用于日志，另一个用于一般存储，可以将读操作的影响和对于写操作的延迟分隔开。&lt;/li>
&lt;/ul>
&lt;h2 id="计算存储分离">计算存储分离&lt;/h2>
&lt;p>解决的问题：避免 broker 扩容时 partition 的数据迁移。&lt;/p>
&lt;p>解决方案：原来 broker 同时负责计算（提供服务给生产者和消费者）和存储（消息的持久化）。Plusar 将两者分离，改用多层的计算存储分离架构，broker 只负责计算，将存储交给底层存储引擎 Bookkeeper。&lt;/p>
&lt;p>Kafka 中可以把每个 partition 理解成一个存储消息的大文件，在 broker 之间转移 partition 需要复制数据。在 Pulsar 中可以把每个 partition 理解成一个文件描述符，broker 只需要持有该文件描述符即可，可以把数据的处理全部交给存储引擎 Bookkeeper。且因为 broker 是无状态的，可以非常方便地借助 kubernetes 实现弹性扩缩容等。&lt;/p>
&lt;p>如果某个 broker 节点压力很大，增加 broker 节点去分担 partition 即可。与之类似的如果某个 broker 节点宕机，直接转移 partition 到其它 broker 即可，这些操作都不涉及数据复制。&lt;/p>
&lt;h2 id="对等节点">对等节点&lt;/h2>
&lt;p>Kafka 使用主从复制的方式实现高可用；Bookkeeper 采用 Quorum 机制实现高可用。&lt;/p>
&lt;p>Bookkeeper 集群由若干 bookie 节点（运行着 bookie 进程的服务器）组成的，和 Kafka 的主从复制机制不同，这些 bookie 节点都是对等的没有主从之分。&lt;/p>
&lt;p>数据写入方式，条带化写入：当 broker 要求 Bookkeeper 集群存储一条消息（entry）时，该消息会被并发地同时写入多个 bookie 节点进行存储。之后的消息会以滚动的方式选取不同的 bookie 节点进行写入。&lt;/p>
&lt;p>这种写入方式既实现了数据的冗余存储，又使得数据能够均匀分布在多个存储节点上，从而避免数据倾斜导致某个存储节点压力过大。&lt;/p>
&lt;p>对等节点的好处在于可以进行快速故障恢复和扩容。&lt;/p>
&lt;p>Bookkeeper 中维护了类似下面的一组元数据：&lt;/p>
&lt;style>
.td-content .highlight {
margin-top: 0.5rem;
margin-bottom: 0.5rem;
}
.code-collapse1 {
overflow-y: auto;
max-height: 500px;
overflow-x: auto;
max-width: 100%;
}
&lt;/style>
&lt;div class="code-collapse1">
&lt;div class="highlight">&lt;div style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-plain" data-lang="plain">&lt;span style="display:flex;">&lt;span>[bookie1, bookie2, bookie3], 0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>[bookie1, bookie3, bookie4], 100
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>这组元数据的含义是：entry0 ~ entry99 都写到了 bookie1, bookie2, bookie3 中，entry100及之后的消息都写到了 bookie1, bookie3, bookie4 中。
这组元数据记录了每条 entry 具体的位置，即便 bookie2 节点故障，还有其它节点如 bookie1, bookie3 节点可以读取。&lt;/p>
&lt;h2 id="读写分离">读写分离&lt;/h2>
&lt;p>bookie 节点实现读写隔离，不再依赖操作系统的 Page Cache，而是自行维护缓存，保证了数据可靠性和高性能。&lt;/p>
&lt;p>&lt;img src="../imgs/20230114_pulsar_2.png" alt="20230114_pulsar_2.png">&lt;/p>
&lt;p>每个 bookie 节点都拥有两块磁盘，其中 Journal 磁盘专门用于写入数据，Entry Log 磁盘专门用于读取数据，而 memtable 是 bookie 节点自行维护的读写缓存。&lt;/p>
&lt;p>其中 Journal 盘的写入不依赖 Page Cache，直接强制刷盘（可以配置），写入完成后 bookie 节点就会返回 ACK 写入成功。&lt;/p>
&lt;p>写 Journal 盘的同时，数据还会在 memotable 缓存中写一份，memotable 会对数据进行排序，一段时间后刷入 Entry Log 盘。&lt;/p>
&lt;p>这样不仅多了一层缓存，而且 Entry Log 盘中的数据有一定的有序性，在读取数据时可以一定程度上提高性能。&lt;/p>
&lt;h3 id="写流程">写流程&lt;/h3>
&lt;p>Broker 数据写入流程如下：&lt;/p>
&lt;ol>
&lt;li>将写请求记入 WAL&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>一般工程实践上建议把 WAL 和数据存储文件分别存储到两种存储盘上，如把 WAL 存入一个 SSD 盘，而数据文件存入另一个 SSD 或者 SATA 盘。&lt;/p>
&lt;/blockquote>
&lt;ol start="2">
&lt;li>将数据写入内存缓存中&lt;/li>
&lt;li>写缓存写满后，进行数据排序并进行 Flush 操作，排序时将同一个 Ledger 的数据聚合后以时间先后进行排序，以便数据读取时快速顺序读取；&lt;/li>
&lt;li>将 &amp;lt;(LedgerID, EntryID), EntryLogID&amp;gt; 写入 RocksDB。&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>LedgerID 相当于 kafka 的 ParitionID，EntryID 即是 Log Message 的逻辑 ID，EntryLogId 就是 Log消息在 Pulsar Fragment文件的物理 Offset。
这里把这个映射关系存储 RocksDB 只是为了加快写入速度，其自身并不是 Pulsar Bookie 的关键组件。&lt;/p>
&lt;/blockquote>
&lt;h3 id="读流程">读流程&lt;/h3>
&lt;p>Bookie 数据读取流程如下：&lt;/p>
&lt;ol>
&lt;li>从写缓存读取数据，写缓存有最新的数据；&lt;/li>
&lt;li>如果写缓存不命中，则从读缓存读取数据；&lt;/li>
&lt;li>如果读缓存不命中，则根据 RocksDB 存储的映射关系查找消息对应的物理存储位置，然后从磁盘上读取数据；&lt;/li>
&lt;li>把从磁盘读取的数据回填到读缓存中；&lt;/li>
&lt;li>返回数据给 Broker。&lt;/li>
&lt;/ol>
&lt;h3 id="优缺点">优缺点&lt;/h3>
&lt;p>这样设计的缺点是一份数据要存两次，消耗磁盘空间，但优势也很明显：&lt;/p>
&lt;p>1、可靠性得到保证，不会丢失数据。因为 Journal 落盘后才判定为写入成功，即使机器断电数据也不会丢失。&lt;/p>
&lt;p>2、数据读写不依赖操作系统的 Page Cache，即便读写压力较大，也可以保证稳定的性能。&lt;/p>
&lt;p>3、可以灵活配置。Journal 盘的数据可以定时迁出，可以采用存储空间较小但写入速度快的存储设备来提高写入性能。&lt;/p>
&lt;h1 id="对比kafka">对比Kafka&lt;/h1>
&lt;h2 id="名词对应表">名词对应表&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">Pulsar&lt;/th>
&lt;th style="text-align:left">Kafka&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">Topic&lt;/td>
&lt;td style="text-align:left">Topic&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Partition&lt;/td>
&lt;td style="text-align:left">Partition&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Ledger(Segment)/Fragment&lt;/td>
&lt;td style="text-align:left">Fragment/Segment&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Bookie&lt;/td>
&lt;td style="text-align:left">Broker&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Broker&lt;/td>
&lt;td style="text-align:left">Client SDK&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Ensemble Size&lt;/td>
&lt;td style="text-align:left">metadata.broker.list&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Write Quorum Size (Qw)&lt;/td>
&lt;td style="text-align:left">Replica Number&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Ack Quorum Size (Qa)&lt;/td>
&lt;td style="text-align:left">request.required.acks&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="优劣势">优劣势&lt;/h2>
&lt;p>优势：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>计算存储分离，避免数据拷贝&lt;/p>
&lt;/li>
&lt;li>
&lt;p>无状态：可以快速扩容、故障恢复&lt;/p>
&lt;/li>
&lt;li>
&lt;p>稳定性更佳：&lt;a href="https://openmessaging.cloud/docs/benchmarks/pulsar/">https://openmessaging.cloud/docs/benchmarks/pulsar/&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>更多的特性支持：Pulsar 提供了很多与 Kafka 相似的特性，比如跨域复制、流式消息处理（Pulsar Functions）、连接器（Pulsar IO）、基于 SQL 的主题查询（Pulsar SQL）、schema registry，还有一些 Kafka 没有的特性，比如分层存储和多租户。
劣势：&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Pulsar 项目较新，社区活跃不足，而 Kafka 更加成熟，社区更活跃&lt;/p>
&lt;/li>
&lt;li>
&lt;p>kafka 仅依赖 broker 和 zookeeper，而 Pulsar 还依赖 bookKeeper，增加了系统的复杂性。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="reference">Reference&lt;/h1>
&lt;p>&lt;a href="https://pulsar.apache.org/docs/2.11.x/concepts-overview/">Pulsar&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://alexstocks.github.io/html/pulsar.html">https://alexstocks.github.io/html/pulsar.html&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://www.infoq.cn/article/1uaxfkwuhukty1t_5gpq">比拼 Kafka, 大数据分析新秀 Pulsar 到底好在哪&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://alexstocks.github.io/html/pulsar.html">https://alexstocks.github.io/html/pulsar.html&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://zhuanlan.zhihu.com/p/596415690">重构Kafka&lt;/a>&lt;/p></description></item><item><title>Docs: RocketMQ源码分析</title><link>/docs/43.MQ/RocketMQ%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/43.MQ/RocketMQ%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</guid><description>
&lt;h1 id="源码环境搭建">源码环境搭建&lt;/h1>
&lt;h2 id="源码下载">源码下载&lt;/h2>
&lt;p>&lt;a href="https://github.com/apache/rocketmq">https://github.com/apache/rocketmq&lt;/a>&lt;/p>
&lt;p>可直接clone或下载压缩包，这里以 release-4.7.1 版本为例分析。&lt;/p>
&lt;h2 id="模块启动">模块启动&lt;/h2>
&lt;p>主要模块：&lt;/p>
&lt;p>1、broker：broker 模块&lt;/p>
&lt;p>2、client：客户端（生产者、消费者）&lt;/p>
&lt;p>3、example：示例代码&lt;/p>
&lt;p>4、namesrv：NameServer 实现相关类&lt;/p>
&lt;p>Tips：配置关键代码提示，类似 todo、fixme&lt;/p>
&lt;p>在 IDEA 下方的 TODO 中，点击 Filter 图标的 Edit Filters。配置 Patterns，如 &lt;code>\bk1&lt;/code> 、 &lt;code>\bk2&lt;/code> 、 &lt;code>\bkkk&lt;/code> 等；配置 Filters ，选择 刚才配置的 patterns。&lt;/p>
&lt;p>参考链接：&lt;a href="https://www.jetbrains.com.cn/help/idea/using-todo.html">https://www.jetbrains.com.cn/help/idea/using-todo.html&lt;/a>&lt;/p>
&lt;h3 id="源码调试">源码调试&lt;/h3>
&lt;p>Execute Maven Goal（IDEA 右边栏 maven 图标）&lt;/p>
&lt;style>
.td-content .highlight {
margin-top: 0.5rem;
margin-bottom: 0.5rem;
}
.code-collapse1 {
overflow-y: auto;
max-height: 500px;
overflow-x: auto;
max-width: 100%;
}
&lt;/style>
&lt;div class="code-collapse1">
&lt;div class="highlight">&lt;div style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>clean install -Dmaven.test.skip&lt;span style="color:#000">=&lt;/span>&lt;span style="color:#a90d91">true&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h3 id="配置文件">配置文件&lt;/h3>
&lt;p>在根目录下新建 conf 文件夹，将 distribution/conf 下 broker.conf、logback_broker.xml、logback_namesrv.xml、logback_tools.xml 拷贝到该目录下。&lt;/p>
&lt;h3 id="启动-namesrv">启动 namesrv&lt;/h3>
&lt;style>
.td-content .highlight {
margin-top: 0.5rem;
margin-bottom: 0.5rem;
}
.code-collapse1 {
overflow-y: auto;
max-height: 500px;
overflow-x: auto;
max-width: 100%;
}
&lt;/style>
&lt;div class="code-collapse1">
&lt;div class="highlight">&lt;div style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">org&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">apache&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">rocketmq&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">namesrv&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">NamesrvStartup&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#177500">// 指定环境变量，项目根目录，用于找其下的 conf 目录
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#177500">&lt;/span>&lt;span style="color:#000">ROCKETMQ_HOME&lt;/span>&lt;span style="color:#000">=/&lt;/span>&lt;span style="color:#000">Users&lt;/span>&lt;span style="color:#000">/&lt;/span>&lt;span style="color:#000">bo&lt;/span>&lt;span style="color:#000">/&lt;/span>&lt;span style="color:#000">source_code&lt;/span>&lt;span style="color:#000">/&lt;/span>&lt;span style="color:#000">rocketmq&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#177500">// 启动成功，会出现如下日志
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#177500">&lt;/span>&lt;span style="color:#000">The&lt;/span> &lt;span style="color:#000">Name&lt;/span> &lt;span style="color:#000">Server&lt;/span> &lt;span style="color:#000">boot&lt;/span> &lt;span style="color:#000">success&lt;/span>&lt;span style="color:#000">.&lt;/span> &lt;span style="color:#000">serializeType&lt;/span>&lt;span style="color:#000">=&lt;/span>&lt;span style="color:#000">JSON&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h3 id="启动-broker">启动 broker&lt;/h3>
&lt;style>
.td-content .highlight {
margin-top: 0.5rem;
margin-bottom: 0.5rem;
}
.code-collapse1 {
overflow-y: auto;
max-height: 500px;
overflow-x: auto;
max-width: 100%;
}
&lt;/style>
&lt;div class="code-collapse1">
&lt;div class="highlight">&lt;div style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">org&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">apache&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">rocketmq&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">broker&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">BrokerStartup&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#177500">// 指定环境变量，项目根目录，用于找其下的 conf 目录
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#177500">&lt;/span>&lt;span style="color:#000">ROCKETMQ_HOME&lt;/span>&lt;span style="color:#000">=/&lt;/span>&lt;span style="color:#000">Users&lt;/span>&lt;span style="color:#000">/&lt;/span>&lt;span style="color:#000">bo&lt;/span>&lt;span style="color:#000">/&lt;/span>&lt;span style="color:#000">source_code&lt;/span>&lt;span style="color:#000">/&lt;/span>&lt;span style="color:#000">rocketmq&lt;/span>&lt;span style="color:#000">;&lt;/span>&lt;span style="color:#000">NAMESRV_ADDR&lt;/span>&lt;span style="color:#000">=&lt;/span>&lt;span style="color:#000">127&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">0&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">0&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">1&lt;/span>&lt;span style="color:#000">:&lt;/span>&lt;span style="color:#000">9876&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#177500">// 指定程序参数
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#177500">&lt;/span>&lt;span style="color:#000">-&lt;/span>&lt;span style="color:#000">c&lt;/span> &lt;span style="color:#000">/&lt;/span>&lt;span style="color:#000">Users&lt;/span>&lt;span style="color:#000">/&lt;/span>&lt;span style="color:#000">bo&lt;/span>&lt;span style="color:#000">/&lt;/span>&lt;span style="color:#000">source_code&lt;/span>&lt;span style="color:#000">/&lt;/span>&lt;span style="color:#000">rocketmq&lt;/span>&lt;span style="color:#000">/&lt;/span>&lt;span style="color:#000">conf&lt;/span>&lt;span style="color:#000">/&lt;/span>&lt;span style="color:#000">broker&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">conf&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#177500">// 启动成功
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#177500">&lt;/span>&lt;span style="color:#000">The&lt;/span> &lt;span style="color:#000">broker&lt;/span>&lt;span style="color:#000">[&lt;/span>&lt;span style="color:#000">broker&lt;/span>&lt;span style="color:#000">-&lt;/span>&lt;span style="color:#000">a&lt;/span>&lt;span style="color:#000">,&lt;/span> &lt;span style="color:#000">192&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">168&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">2&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">104&lt;/span>&lt;span style="color:#000">:&lt;/span>&lt;span style="color:#000">10911&lt;/span>&lt;span style="color:#000">]&lt;/span> &lt;span style="color:#000">boot&lt;/span> &lt;span style="color:#000">success&lt;/span>&lt;span style="color:#000">.&lt;/span> &lt;span style="color:#000">serializeType&lt;/span>&lt;span style="color:#000">=&lt;/span>&lt;span style="color:#000">JSON&lt;/span> &lt;span style="color:#000">and&lt;/span> &lt;span style="color:#000">name&lt;/span> &lt;span style="color:#000">server&lt;/span> &lt;span style="color:#000">is&lt;/span> &lt;span style="color:#000">127&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">0&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">0&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">1&lt;/span>&lt;span style="color:#000">:&lt;/span>&lt;span style="color:#000">9876&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h3 id="启动-consumer">启动 consumer&lt;/h3>
&lt;style>
.td-content .highlight {
margin-top: 0.5rem;
margin-bottom: 0.5rem;
}
.code-collapse1 {
overflow-y: auto;
max-height: 500px;
overflow-x: auto;
max-width: 100%;
}
&lt;/style>
&lt;div class="code-collapse1">
&lt;div class="highlight">&lt;div style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">org&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">apache&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">rocketmq&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">example&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">quickstart&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">Consumer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#177500">// 在 consumer.setConsumeFromWhere xx 前指定 namesrv addr
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#177500">&lt;/span>&lt;span style="color:#000">consumer&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">setNamesrvAddr&lt;/span>&lt;span style="color:#000">(&lt;/span>&lt;span style="color:#c41a16">&amp;#34;127.0.0.1:9876&amp;#34;&lt;/span>&lt;span style="color:#000">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#177500">// 或配置环境变量
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#177500">&lt;/span>&lt;span style="color:#000">NAMESRV_ADDR&lt;/span>&lt;span style="color:#000">=&lt;/span>&lt;span style="color:#000">127&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">0&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">0&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">1&lt;/span>&lt;span style="color:#000">:&lt;/span>&lt;span style="color:#000">9876&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h3 id="启动-producer">启动 producer&lt;/h3>
&lt;style>
.td-content .highlight {
margin-top: 0.5rem;
margin-bottom: 0.5rem;
}
.code-collapse1 {
overflow-y: auto;
max-height: 500px;
overflow-x: auto;
max-width: 100%;
}
&lt;/style>
&lt;div class="code-collapse1">
&lt;div class="highlight">&lt;div style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">org&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">apache&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">rocketmq&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">example&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">quickstart&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">Producer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#177500">// 在 producer.start(); 前指定 namesrv addr
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#177500">&lt;/span>&lt;span style="color:#000">producer&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">setNamesrvAddr&lt;/span>&lt;span style="color:#000">(&lt;/span>&lt;span style="color:#c41a16">&amp;#34;127.0.0.1:9876&amp;#34;&lt;/span>&lt;span style="color:#000">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#177500">// 或配置环境变量
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#177500">&lt;/span>&lt;span style="color:#000">NAMESRV_ADDR&lt;/span>&lt;span style="color:#000">=&lt;/span>&lt;span style="color:#000">127&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">0&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">0&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">1&lt;/span>&lt;span style="color:#000">:&lt;/span>&lt;span style="color:#000">9876&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h1 id="namesrv">NameSrv&lt;/h1>
&lt;h2 id="nameserver整体结构">NameServer整体结构&lt;/h2>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_1.png" alt="20221231_rocketmq_1.png">&lt;/p>
&lt;h1 id="broker">Broker&lt;/h1>
&lt;h2 id="broker架构图">Broker架构图&lt;/h2>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_2.png" alt="20221231_rocketmq_2.png">&lt;/p>
&lt;h2 id="broker-注册">Broker 注册&lt;/h2>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_3.png" alt="20221231_rocketmq_3.png">&lt;/p>
&lt;h1 id="senddefaultimpl">sendDefaultImpl&lt;/h1>
&lt;style>
.td-content .highlight {
margin-top: 0.5rem;
margin-bottom: 0.5rem;
}
.code-collapse1 {
overflow-y: auto;
max-height: 500px;
overflow-x: auto;
max-width: 100%;
}
&lt;/style>
&lt;div class="code-collapse1">
&lt;div class="highlight">&lt;div style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">org&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">apache&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">rocketmq&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">client&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">impl&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">producer&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">DefaultMQProducerImpl&lt;/span>&lt;span style="color:#000">#&lt;/span>&lt;span style="color:#000">sendDefaultImpl&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="checkmessage">checkMessage&lt;/h2>
&lt;style>
.td-content .highlight {
margin-top: 0.5rem;
margin-bottom: 0.5rem;
}
.code-collapse1 {
overflow-y: auto;
max-height: 500px;
overflow-x: auto;
max-width: 100%;
}
&lt;/style>
&lt;div class="code-collapse1">
&lt;div class="highlight">&lt;div style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">Validators&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">checkMessage&lt;/span>&lt;span style="color:#000">(&lt;/span>&lt;span style="color:#000">msg&lt;/span>&lt;span style="color:#000">,&lt;/span> &lt;span style="color:#a90d91">this&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">defaultMQProducer&lt;/span>&lt;span style="color:#000">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="trytofindtopicpublishinfo">tryToFindTopicPublishInfo&lt;/h2>
&lt;style>
.td-content .highlight {
margin-top: 0.5rem;
margin-bottom: 0.5rem;
}
.code-collapse1 {
overflow-y: auto;
max-height: 500px;
overflow-x: auto;
max-width: 100%;
}
&lt;/style>
&lt;div class="code-collapse1">
&lt;div class="highlight">&lt;div style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a90d91">this&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">tryToFindTopicPublishInfo&lt;/span>&lt;span style="color:#000">(&lt;/span>&lt;span style="color:#000">msg&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">getTopic&lt;/span>&lt;span style="color:#000">());&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="selectonemessagequeue">selectOneMessageQueue&lt;/h2>
&lt;style>
.td-content .highlight {
margin-top: 0.5rem;
margin-bottom: 0.5rem;
}
.code-collapse1 {
overflow-y: auto;
max-height: 500px;
overflow-x: auto;
max-width: 100%;
}
&lt;/style>
&lt;div class="code-collapse1">
&lt;div class="highlight">&lt;div style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a90d91">this&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">selectOneMessageQueue&lt;/span>&lt;span style="color:#000">(&lt;/span>&lt;span style="color:#000">topicPublishInfo&lt;/span>&lt;span style="color:#000">,&lt;/span> &lt;span style="color:#000">lastBrokerName&lt;/span>&lt;span style="color:#000">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>Message Queue选择机制&lt;/p>
&lt;h2 id="updatefaultitem">updateFaultItem&lt;/h2>
&lt;style>
.td-content .highlight {
margin-top: 0.5rem;
margin-bottom: 0.5rem;
}
.code-collapse1 {
overflow-y: auto;
max-height: 500px;
overflow-x: auto;
max-width: 100%;
}
&lt;/style>
&lt;div class="code-collapse1">
&lt;div class="highlight">&lt;div style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a90d91">this&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">updateFaultItem&lt;/span>&lt;span style="color:#000">(&lt;/span>&lt;span style="color:#000">mq&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">getBrokerName&lt;/span>&lt;span style="color:#000">(),&lt;/span> &lt;span style="color:#000">endTimestamp&lt;/span> &lt;span style="color:#000">-&lt;/span> &lt;span style="color:#000">beginTimestampPrev&lt;/span>&lt;span style="color:#000">,&lt;/span> &lt;span style="color:#a90d91">true&lt;/span>&lt;span style="color:#000">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>容错机制下的选择逻辑&lt;/p>
&lt;h1 id="producer">Producer&lt;/h1>
&lt;h2 id="producer-功能">Producer 功能&lt;/h2>
&lt;p>Producer 有两种：&lt;/p>
&lt;p>1、普通发送者 DefaultMQProducer。只需要构建一个 Netty 客户端，往 Broker 发送消息即可。&lt;/p>
&lt;p>注意：异步回调只是在 Producer 接收到 Broker 的响应后自行调整流程，不需要提供 Netty 服务。&lt;/p>
&lt;p>2、事务消息发送者 TransactionMQProducer。需要构建一个 Netty 客户端，往 Broker 发送消息。同时也要构建 Netty 服务端，供 Broker 回查本地事务状态。&lt;/p>
&lt;h2 id="producer-总体流程">Producer 总体流程&lt;/h2>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_4.png" alt="20221231_rocketmq_4.png">&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_5.png" alt="20221231_rocketmq_5.png">&lt;/p>
&lt;h2 id="检查消息合法性">检查消息合法性&lt;/h2>
&lt;p>&lt;strong>org.apache.rocketmq.client.Validators#checkMessage&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Topic名称中是否包含了非法字符&lt;/li>
&lt;li>Topic名称长度是否超过了最大的长度限制，由常量TOPIC_MAX_LENGTH来决定，其默认值为127&lt;/li>
&lt;li>当前消息体是否是NULL或者是空消息&lt;/li>
&lt;li>当前消息体是否超过了最大限制，由常量maxMessageSize决定，值为1024 * 1024 * 4，也就是4M。
&lt;img src="../imgs/20221231_rocketmq_6.png" alt="20221231_rocketmq_6.png">&lt;/li>
&lt;/ul>
&lt;h2 id="获取topic的详情">获取Topic的详情&lt;/h2>
&lt;style>
.td-content .highlight {
margin-top: 0.5rem;
margin-bottom: 0.5rem;
}
.code-collapse1 {
overflow-y: auto;
max-height: 500px;
overflow-x: auto;
max-width: 100%;
}
&lt;/style>
&lt;div class="code-collapse1">
&lt;div class="highlight">&lt;div style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">org&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">apache&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">rocketmq&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">client&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">impl&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">producer&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">DefaultMQProducerImpl&lt;/span>&lt;span style="color:#000">#&lt;/span>&lt;span style="color:#000">tryToFindTopicPublishInfo&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>当通过了消息的合法性校验之后，需要知道应该把消息发送给谁，此时就需要通过当前消息所属的Topic拿到Topic的详细数据。
&lt;img src="../imgs/20221231_rocketmq_7.png" alt="20221231_rocketmq_7.png">&lt;/p>
&lt;p>获取Topic的方法源码在上面已经给出来了，首先会从内存中维护的一份Map中获取数据。顺带一提，这里的Map是ConcurrentHashMap，是线程安全的，和Golang中的Sync.Map类似。&lt;/p>
&lt;p>当然，首次发送 Map 肯定是空的，此时会调用NameServer的接口，通过Topic去获取详情的Topic数据，会在上面的方法中将其加入到Map中去，这样一来下次再往该Topic发送消息就能够直接从内存中获取。这里就是简单的实现的缓存机制 。&lt;/p>
&lt;p>从方法名称来看，是通过Topic获取路由数据。实际上该方法，通过调用NameServer提供的API，更新了两部分数据，分别是：&lt;/p>
&lt;p>1）Topic路由信息&lt;/p>
&lt;p>2）Topic下的Broker相关信息&lt;/p>
&lt;p>而这两部分数据都来源于同一个结构体TopicRouteData。&lt;/p>
&lt;p>注意 TopicPublishInfo 这个结构体，包含 TopicRouteData&lt;/p>
&lt;h2 id="producer-路由信息">Producer 路由信息&lt;/h2>
&lt;p>当获取到了需要发送到的Broker详情，包括地址和MessageQueue，那么此时问题的关注点是具体发送到哪一个Message Queue中去。&lt;/p>
&lt;p>核心代码：&lt;/p>
&lt;style>
.td-content .highlight {
margin-top: 0.5rem;
margin-bottom: 0.5rem;
}
.code-collapse1 {
overflow-y: auto;
max-height: 500px;
overflow-x: auto;
max-width: 100%;
}
&lt;/style>
&lt;div class="code-collapse1">
&lt;div class="highlight">&lt;div style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">org&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">apache&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">rocketmq&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">client&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">impl&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">producer&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">DefaultMQProducerImpl&lt;/span>&lt;span style="color:#000">#&lt;/span>&lt;span style="color:#000">tryToFindTopicPublishInfo&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>路由信息的管理流程
&lt;img src="../imgs/20221231_rocketmq_8.png" alt="20221231_rocketmq_8.png">&lt;/p>
&lt;h2 id="producer-负载均衡">Producer 负载均衡&lt;/h2>
&lt;p>默认会把消息平均地发送到所有 MessageQueue 里，这时设计到 Message Queue 的选择机制&lt;/p>
&lt;h3 id="messagequeue-核心选择逻辑">MessageQueue 核心选择逻辑&lt;/h3>
&lt;p>流程图&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_9.png" alt="20221231_rocketmq_9.png">&lt;/p>
&lt;p>核心逻辑，用大白话讲就是将一个随机数和 Message Queue（TopicPublishInfo中）的容量取模。这个随机数存储在 Thread Local 中，首次计算的时候，会直接随机一个数。&lt;/p>
&lt;style>
.td-content .highlight {
margin-top: 0.5rem;
margin-bottom: 0.5rem;
}
.code-collapse1 {
overflow-y: auto;
max-height: 500px;
overflow-x: auto;
max-width: 100%;
}
&lt;/style>
&lt;div class="code-collapse1">
&lt;div class="highlight">&lt;div style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">org&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">apache&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">rocketmq&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">client&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">common&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">ThreadLocalIndex&lt;/span>&lt;span style="color:#000">#&lt;/span>&lt;span style="color:#000">getAndIncrement&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">org&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">apache&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">rocketmq&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">client&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">latency&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">MQFaultStrategy&lt;/span>&lt;span style="color:#000">#&lt;/span>&lt;span style="color:#000">selectOneMessageQueue&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>可以看到，主逻辑被变量 sendLatencyFaultEnable 分为了两部分。&lt;/p>
&lt;h3 id="容错机制下的选择逻辑">容错机制下的选择逻辑&lt;/h3>
&lt;p>该变量表意为发送延迟故障。本质上是一种容错的策略，在原有的MessageQueue选择基础上，再过滤掉不可用的Broker，对之前失败的Broker，按一定的时间做退避。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_10.png" alt="20221231_rocketmq_10.png">&lt;/p>
&lt;style>
.td-content .highlight {
margin-top: 0.5rem;
margin-bottom: 0.5rem;
}
.code-collapse1 {
overflow-y: auto;
max-height: 500px;
overflow-x: auto;
max-width: 100%;
}
&lt;/style>
&lt;div class="code-collapse1">
&lt;div class="highlight">&lt;div style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a90d91">this&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">updateFaultItem&lt;/span>&lt;span style="color:#000">(&lt;/span>&lt;span style="color:#000">mq&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#836c28">getBrokerName&lt;/span>&lt;span style="color:#000">(),&lt;/span> &lt;span style="color:#000">endTimestamp&lt;/span> &lt;span style="color:#000">-&lt;/span> &lt;span style="color:#000">beginTimestampPrev&lt;/span>&lt;span style="color:#000">,&lt;/span> &lt;span style="color:#a90d91">true&lt;/span>&lt;span style="color:#000">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>可以看到，如果调用Broker信息发生了异常，那么就会调用 updateFault 这个方法，来更新Broker 的 Aviable 情况。注意这个参数 isolation 的值为 true。接下来从源码级别来验证上面说的退避 3000ms 的事实。
可以看到，isolation 值是 true，则 duration 通过三元运算符计算出来结果为 30000，也就是 30 秒。所以可以得出结论，如果发送消息抛出了异常，那么直接会将该 Broker 设置为 30 秒内不可用。&lt;/p>
&lt;p>而如果只是发送延迟较高，则会根据如下的 map，根据延迟的具体时间，来判断该设置多少时间的不可用。&lt;/p>
&lt;h3 id="正常情况下的选择逻辑">正常情况下的选择逻辑&lt;/h3>
&lt;p>而正常情况下，如果当前发送故障延迟没有启用，则会走常规逻辑，同样的会去for循环计算，循环中取到了 MessageQueue 之后会去判断是否和上次选择的 MessageQueue 属于同一个Broker，如果是同一个 Broker，则会重新选择，直到选择到不属于同一个 Broker 的 MessageQueue，或者直到循环结束。这也是为了将消息均匀的分发存储，防止数据倾斜。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_11.png" alt="20221231_rocketmq_11.png">&lt;/p>
&lt;h2 id="发送消息">发送消息&lt;/h2>
&lt;p>选到了具体的Message Queue之后就会开始执行发送消息的逻辑，就会调用底层Netty的接口给发送出去，这块暂时没啥可看的。&lt;/p>
&lt;h1 id="broker的启动流程">Broker的启动流程&lt;/h1>
&lt;h2 id="主从同步">主从同步&lt;/h2>
&lt;p>在上面提到过，RocketMQ有自己的主从同步，但是有两个不同的版本，版本的分水岭是在4.5版本。这两个版本区别是什么呢？&lt;/p>
&lt;p>1）4.5之前：有点类似于Redis中，我们手动的将某台机器通过命令slave of 变成另一台Redis的Slave节点，这样一来就变成了一个较为原始的一主一从的架构。为什么说原始呢？因为如果此时Master节点宕机，我们需要人肉的去做故障转移。RocketMQ的主从架构也是这种情况。&lt;/p>
&lt;p>2）4.5之后：引入了Dleger，可以实现一主多从，并且实现自动的故障转移。这就跟Redis后续推出了Sentinel是一样的。Dleger也是类似的作用。&lt;/p>
&lt;p>下图是Broker启动代码中的源码。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_12.png" alt="20221231_rocketmq_12.png">&lt;/p>
&lt;p>可以看到判断了是否开启了Dleger，默认是不开启的。所以就会执行其中的逻辑。&lt;/p>
&lt;p>刚好我们就看到了，里面有&lt;strong>Rocket主从同步数据&lt;/strong>的相关代码。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_13.png" alt="20221231_rocketmq_13.png">&lt;/p>
&lt;p>如果当前Broker节点的角色是Slave，则会启动一个周期性的定时任务，定期（也就是10秒）去Master Broker同步全量的数据。同步的数据包括：&lt;/p>
&lt;p>1）Topic的相关配置&lt;/p>
&lt;p>2）Cosumer的消费偏移量&lt;/p>
&lt;p>3）延迟消息的Offset&lt;/p>
&lt;p>4）订阅组的相关数据和配置&lt;/p>
&lt;h2 id="注册broker">注册Broker&lt;/h2>
&lt;p>完成了主动同步定时任务的启动之后，就会去调用registerBrokerAll去注册Broker。可能这里会有点疑问，我这里是Broker启动，只有当前一个Broker实例，那这个All是什么意思呢？&lt;/p>
&lt;p>All是指所有的NameServer，Broker启动的时候会将自己注册到每一个NameServer上去。为什么不只注册到一个NameServer就完事了呢？这样一来还可以提高效率。归根结底还是高可用的问题。&lt;/p>
&lt;p>如果Broker只注册到了一台NameServer上，万一这台NameServer挂了呢？这个Broker对所有客户端就都不可见了。实际上Broker还在正常的运行。&lt;/p>
&lt;p>进到registerBrokerAll中去。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_14.png" alt="20221231_rocketmq_14.png">&lt;/p>
&lt;p>可以看到，这里会判断是否需要进行注册。通过上面的截图可以看到，此时forceRegister的值为true，而是否要注册，决定权就交给了needRegister&lt;/p>
&lt;p>为什么需要判断是否需要注册呢？因为Broker一旦注册到了NameServer之后，由于Producer不停的在写入数据，Consumer也在不停的消费数据，Broker也可能因为故障导致某些Topic下的Message Queue等关键的路由信息发生变动。&lt;/p>
&lt;p>这样一来，NameServer中的数据和Broker中的数据就会不一致。&lt;/p>
&lt;h2 id="如何判断是否需要注册">如何判断是否需要注册&lt;/h2>
&lt;p>大致的思路是，Broker会从每一个NameServer中获取到当前Broker的数据，并和当前Broker节点中的数据做对比。但凡有一台NameServer数据和当前Broker不一致，都会进行注册操作。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_15.png" alt="20221231_rocketmq_15.png">&lt;/p>
&lt;p>接下来，我们从源码层面验证这个逻辑。关键的逻辑在图中也标注了出来。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_16.png" alt="20221231_rocketmq_16.png">&lt;/p>
&lt;p>可以看到， 就是通过对比Broker中的数据版本和NameServer中的数据版本来实现的。这个版本，注册的时候会写到注册的数据中存入NameServer中。&lt;/p>
&lt;p>这里由于是有多个，所以RocketMQ用线程池来实现了多线程操作，并且用CountDownLatch来等待所有的返回结果。经典的用空间换时间，Golang里面也有类似的操作，那就是sync.waitGroup。&lt;/p>
&lt;p>关于任何一个数据不匹配，都会进行重新注册的事实，我们也从源码层面来验证一下。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_17.png" alt="20221231_rocketmq_17.png">&lt;/p>
&lt;p>可以看到，如果任何一台NameServer的数据发生了Change，都会break，返回true。&lt;/p>
&lt;p>这里的结果列表使用的是CopyOnWriteList来实现的。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_18.png" alt="20221231_rocketmq_18.png">&lt;/p>
&lt;p>因为这里是多线程去执行的判断逻辑，而正常的列表不是线程安全的。CopyOnWriteArrayList之所以是线程安全的，这归功于COW（Copy On Write），读请求时共用同一个List，涉及到写请求时，会复制出一个List，并在写入数据的时候加入独占锁。比起直接对所有操作加锁，读写锁的形式分离了读、写请求，使其互不影响，只对写请求加锁，降低了加锁的次数、减少了加锁的消耗，提升了整体操作的并发。&lt;/p>
&lt;h2 id="执行注册逻辑">执行注册逻辑&lt;/h2>
&lt;p>这块就是构建数据，然后多线程并发的去发送请求，用CopyOnWriteArrayList来保存结果。不过，上面我们提到过，Broker注册的时候，会把数据版本发送到NameServer并且存储起来，这块我们可以看看发送到NameServer的数据结构。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_19.png" alt="20221231_rocketmq_19.png">&lt;/p>
&lt;p>可以看到，Topic的数据分为了两部分，一部分是核心的逻辑，另一部分是DataVersion，也就是我们刚刚一直提到的数据版本。&lt;/p>
&lt;h1 id="消息存储">消息存储&lt;/h1>
&lt;p> &lt;/p>
&lt;p>源码入口：&lt;/p>
&lt;style>
.td-content .highlight {
margin-top: 0.5rem;
margin-bottom: 0.5rem;
}
.code-collapse1 {
overflow-y: auto;
max-height: 500px;
overflow-x: auto;
max-width: 100%;
}
&lt;/style>
&lt;div class="code-collapse1">
&lt;div class="highlight">&lt;div style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-plain" data-lang="plain">&lt;span style="display:flex;">&lt;span>org.apache.rocketmq.store.DefaultMessageStore#start
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="commit-log">Commit log&lt;/h2>
&lt;p>流程图&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_20.png" alt="20221231_rocketmq_20.png">&lt;/p>
&lt;p>Producer 发送的消息是存储在一种叫 commit log 的文件中的，Producer 端每次写入的消息是不等长的，当该 CommitLog 文件写入满 1G，就会新建另一个新的 CommitLog，继续写入。此次采取的是顺序写入。&lt;/p>
&lt;p>那么问题来了，Consumer 来消费的时候，Broker 是如何快速找到对应的消息的呢？首先排除遍历文件查找的方法， 因为 RocketMQ 是以高吞吐、高性能著称的，肯定不可能采取这种对于很慢的操作。那RocketMQ是如何做的呢？答案是 ConsumerQueue。&lt;/p>
&lt;h2 id="consumerqueue">ConsumerQueue&lt;/h2>
&lt;p>ConsumerQueue是什么？是文件。引入的目的是什么呢？提高消费的性能。&lt;/p>
&lt;p>Broker在收到一条消息的时候，写入Commit Log的同时，还会将当前这条消息在commit log中的offset、消息的size和对应的Tag的Hash写入到consumer queue文件中去。&lt;/p>
&lt;p>每个 MessageQueue 都会有对应的 ConsumerQueue 文件存储在磁盘上，每个 ConsumerQueue 文件包含了30W条消息，每条消息的 size 大小为 20 字节，包含了 8 字节 CommitLog 的 Offset、4 字节的消息长度、8 字节的 Tag 的哈希值。这样一来，每个ConsumerQueue 的文件大小就约为5.72M。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_21.png" alt="20221231_rocketmq_21.png">&lt;/p>
&lt;p>当该 ConsumerQueue 文件写满了之后，就会再新建一个 ConsumerQueue 文件，继续写入。&lt;/p>
&lt;p>所以，ConsumerQueue 文件可以看成是 CommitLog 文件的索引。&lt;/p>
&lt;h2 id="文件同步刷盘与异步刷盘">文件同步刷盘与异步刷盘&lt;/h2>
&lt;p>源码入口：&lt;/p>
&lt;style>
.td-content .highlight {
margin-top: 0.5rem;
margin-bottom: 0.5rem;
}
.code-collapse1 {
overflow-y: auto;
max-height: 500px;
overflow-x: auto;
max-width: 100%;
}
&lt;/style>
&lt;div class="code-collapse1">
&lt;div class="highlight">&lt;div style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-plain" data-lang="plain">&lt;span style="display:flex;">&lt;span>org.apache.rocketmq.store.CommitLog#putMessage -&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>org.apache.rocketmq.store.CommitLog#handleDiskFlush
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>其中主要涉及到是否开启了对外内存 TransientStorePoolEnable。如果开启了堆外内存，会在启动时申请一个跟 CommitLog 文件大小一致的堆外内存，这部分内存可以确保不会被交换到虚拟内存中。
 &lt;/p>
&lt;h2 id="过期文件删除">过期文件删除&lt;/h2>
&lt;p>入口：在 DefaultMessageStore 的 start 方法中调用&lt;/p>
&lt;style>
.td-content .highlight {
margin-top: 0.5rem;
margin-bottom: 0.5rem;
}
.code-collapse1 {
overflow-y: auto;
max-height: 500px;
overflow-x: auto;
max-width: 100%;
}
&lt;/style>
&lt;div class="code-collapse1">
&lt;div class="highlight">&lt;div style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-plain" data-lang="plain">&lt;span style="display:flex;">&lt;span>org.apache.rocketmq.store.DefaultMessageStore#addScheduleTask
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p> 
默认情况下，Broker 会启动后台线程，每 60 秒检查 CommitLog、ConsumeQueue 文件。然后对超过 72 小时的数据进行删除。也就是说，默认情况下，RocketMQ 只会保存 3 天内的数据。这个时间可以通过 fileReservedTime 来配置。注意删除时，并不会检查消息是否被消费了。&lt;/p>
&lt;p> &lt;/p>
&lt;p>整个文件存储的核心入口在 DefaultMessageStore 的 start 方法中。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_22.png" alt="20221231_rocketmq_22.png">&lt;/p>
&lt;p> &lt;/p>
&lt;h2 id="文件存储小结">文件存储小结&lt;/h2>
&lt;p>RocketMQ 的存储文件包括消息文件（CommitLog）、消息消费队列文件（ConsumerQueue）、Hash 索引文件（IndexFile）、监测点文件（checkPoint）、abort（关闭异常文件）。单个消息存储文件、消息消费队列文件、Hash 索引文件长度固定以便使用内存映射机制进行文件的读写操作。&lt;/p>
&lt;p> &lt;/p>
&lt;p>RocketMQ 组织文件以文件的起始偏移量来命名文件，这样能够根据偏移量快读定位到真实的物理文件。RocketMQ 基于内存映射文件机制提供了同步刷盘和异步刷盘两种机制，异步刷盘是指在消息存储时先追加到内存映射文件，然后启动专门的刷盘线程定时将内存中的文件数据刷写到磁盘。&lt;/p>
&lt;p> &lt;/p>
&lt;p>CommitLog，消息存储文件，RocketMQ 为了保证消息发送的高吞吐量，采用单一文件存储所有主题消息，保证消息存储时完全的顺序写，但这样给文件读取带来了不便，为此 RocketMQ 为了方便消息消费构建了消息消费队列文件，基于主题与队列进行组织，同时 RocketMQ 为消息实现了 Hash 索引，可以为消息设置索引键，根据索引能够快速从 CommitLog 文件中检索消息。&lt;/p>
&lt;h1 id="consumer">Consumer&lt;/h1>
&lt;h2 id="消费者功能">消费者功能&lt;/h2>
&lt;p>1、消费者分为 拉模式消费者 和 推模式消费者。&lt;/p>
&lt;p>消费者的使用过程也跟生产者差不多，都是先 start 然后开始消费&lt;/p>
&lt;p>2、消费者以消费者组的模式开展。消费者组之间有集群模式和广播模式两种消费模式。&lt;/p>
&lt;p>3、消费者负载均衡，即消费者如何绑定消费队列的&lt;/p>
&lt;p>4、推模式的消费者，MessageListenerConcurrently 和 MessageListenerOrderly 两种消息监听器的处理逻辑，为什么后者能否保证消息顺序&lt;/p>
&lt;p> &lt;/p>
&lt;h2 id="consumer-启动">consumer 启动&lt;/h2>
&lt;p>源码入口：&lt;/p>
&lt;style>
.td-content .highlight {
margin-top: 0.5rem;
margin-bottom: 0.5rem;
}
.code-collapse1 {
overflow-y: auto;
max-height: 500px;
overflow-x: auto;
max-width: 100%;
}
&lt;/style>
&lt;div class="code-collapse1">
&lt;div class="highlight">&lt;div style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-plain" data-lang="plain">&lt;span style="display:flex;">&lt;span>org.apache.rocketmq.client.consumer.DefaultMQPushConsumer#start
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>PullMessageService 主要处理拉取消息服务，RebalanceService 主要处理客户端的负载均衡。&lt;/p>
&lt;h2 id="消费模型">消费模型&lt;/h2>
&lt;p>在Consumer中，默认都是采用集群消费，这块在Consumer的代码中也有体现。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_23.png" alt="20221231_rocketmq_23.png">&lt;/p>
&lt;p>而消费模式的不同，会影响到管理offset的具体实现。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_24.png" alt="20221231_rocketmq_24.png">&lt;/p>
&lt;p>可以看到，当消费模型是广播模式时，Offset的持久化管理会使用实现LocalFileOffsetStorage&lt;/p>
&lt;p>当消费模式是集群消费时，则会使用RemoteBrokerOffsetStore。&lt;/p>
&lt;p>具体原因是什么呢？首先我们得知道广播模式和集群模式的区别在哪儿：&lt;/p>
&lt;p>1）广播模式下，一条消息会被ConsumerGroup中的每一台机器所消费&lt;/p>
&lt;p>2）集群模式下，一条消息只会被ConsumerGroup中的一台机器消费&lt;/p>
&lt;p>所以在广播模式下，每个ConsumerGroup的消费进度都不一样，所以需要由Consumer自身来管理Offset。而集群模式下，同个ConsumerGroup下的消费进度其实是一样的，所以可以交由Broker统一管理。&lt;/p>
&lt;h2 id="消费模式">消费模式&lt;/h2>
&lt;p>消费模式则分为顺序消费和并发消费，分别对应实现MessageListenerOrderly和MessageListenerConcurrently两种方式。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_25.png" alt="20221231_rocketmq_25.png">&lt;/p>
&lt;p>不同的消费方式会采取不同的底层实现，配置完成之后就会调用start。&lt;/p>
&lt;h2 id="消息拉取">消息拉取&lt;/h2>
&lt;p>拉模式：PullMessageService&lt;/p>
&lt;p>PullRequests 里有 messageQueue 和 processQueue，其中 messageQueue 负责拉取消息，拉取后将消息存入 processQueue，进行处理。存入后就可以清空 messageQueue，继续拉取。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_26.png" alt="20221231_rocketmq_26.png">&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_27.png" alt="20221231_rocketmq_27.png">&lt;/p>
&lt;p> &lt;/p>
&lt;p>接下来来看一个跟最最相关的问题，那就是平时消费的消息到底是怎么样从 Broker 发到的 Consumer。在靠近启动 Rebalance 的地方，Consumer 也开启了一个定时拉取消息的线程。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_28.png" alt="20221231_rocketmq_28.png">&lt;/p>
&lt;p>这个线程做了什么事呢？它会不停的从一个维护在内存中的Queue中获取一个在写入的时候就构建好的 PullRequest 对象，调用具体实现去不停的拉取消息了。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_29.png" alt="20221231_rocketmq_29.png">&lt;/p>
&lt;h2 id="处理消息结果">处理消息结果&lt;/h2>
&lt;p>在这里是否开启AutoCommit，所做的处理差不了很多，大家也都知道，唯一区别就在于是否自动的提交Offset。对于处理成功的逻辑也差不多，我们平时业务逻辑中可能也并不关心消费成功的消息。我们更多关注的是如果消费失败了，RocketMQ是怎么处理的？&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_30.png" alt="20221231_rocketmq_30.png">&lt;/p>
&lt;p>这是在AutoCommit下，如果消费失败了的处理逻辑。会记录一个失败的TPS，然后这里有一个非常关键的逻辑，那就是checkReconsumeTimes。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_31.png" alt="20221231_rocketmq_31.png">&lt;/p>
&lt;p>如果当前消息的重试次数，如果大于了最大的重试消费次数，就会把消费发回给Broker。那最大重试次数是如何定义的。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_32.png" alt="20221231_rocketmq_32.png">&lt;/p>
&lt;p>如果值为-1，那么最大次数就是MAX_VALUE，也就是2147483647。这里有点奇怪啊，按照我们平常的认知，难道不是重试16次吗？然后就看到了很骚的一句注释。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_33.png" alt="20221231_rocketmq_33.png">&lt;/p>
&lt;p>-1 means 16 times，这代码确实有点，一言难尽。&lt;/p>
&lt;p>然后，如果超过了最大的次数限制，就会将该消息调用Prodcuer的默认实现，将其发送到死信队列中。当然，死信队列也不是什么特殊的存在，就是一个单独的Topic而已。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_34.png" alt="20221231_rocketmq_34.png">&lt;/p>
&lt;p>通过getRetryTopic来获取的，默认是给当前的ConsumerGroup名称加上一个前缀。&lt;/p>
&lt;h2 id="客户端负载均衡策略">客户端负载均衡策略&lt;/h2>
&lt;p>在消费者示例的 start 方法中，启动 RebalanceService，这个是客户端进行负载均衡策略的启动服务。只负责根据负载均衡策略获取当前客户端分配到的 MessageQueue 示例。&lt;/p>
&lt;p> &lt;/p>
&lt;p>5 种负载均衡策略，可以由 Consumer 的 allocateMessageQueueStrategy 属性来选择。&lt;/p>
&lt;p> &lt;/p>
&lt;p>最常用的是 AllocateMessageQueueAveragely 平均分配和 AllocateMessageQueueAveragelyByCircle 平均轮询分配。&lt;/p>
&lt;p> &lt;/p>
&lt;p>平均分配是把 MessageQueue 按组内的消费者个数平均分配。&lt;/p>
&lt;p>而平均轮询分配就是把 MessageQueue 按组内的消费者一个一个轮询分配。&lt;/p>
&lt;p>举例：6 个队列 q1、q2、q3、q4、q5、q6，分配给 3 个消费者 c1、c2、c3。&lt;/p>
&lt;p>平均分配的结果就是：c1:{q1, q2}, c2:{q3, q4}, c3:{q5, q6}；&lt;/p>
&lt;p>平均轮询分配的结果就是：c1:{q1, q4}, c2:{q2 q5}, c3:{q3, q6}。&lt;/p>
&lt;p> &lt;/p>
&lt;h2 id="并发消费与顺序消费">并发消费与顺序消费&lt;/h2>
&lt;p>消费过程依然是 DefaultMQPushConsumerImpl 的 consumeMessageService。它有 2 个子类 ConsumeMessageServiceConcurrentlyService 和 ConsumeMessageOrderlyService。其中最主要的差别是 ConsumeMessageOrderlyService 会在消费前把队列锁起来，优先保证拉取同一个队列里的消息。&lt;/p>
&lt;p> &lt;/p>
&lt;p>消费过程的入口在 DefaultMQPushConsumerImpl 的 pullMessage 中定义的 PullCallBack 中。&lt;/p>
&lt;h1 id="负载均衡">负载均衡&lt;/h1>
&lt;p>什么意思呢？假设我们总共有6个MessageQueue，然后此时分布在了3台Broker上，每个Broker上包含了两个queue。此时Consumer有3台，我们可以大致的认为每个Consumer负责2个MessageQueue的消费。但是这里有一个原则，那就是一个MessageQueue只能被一台Consumer消费，而一台Consumer可以消费多个MessageQueue。&lt;/p>
&lt;blockquote>
&lt;p>为什么？道理很简单，RocketMQ支持的顺序消费，是指的分区顺序性，也就是在单个MessageQueue中，消息是具有顺序性的，而如果多台Consumer去消费同一个MessageQueue，就很难去保证顺序消费了。&lt;/p>
&lt;/blockquote>
&lt;p>由于有很多个Consumer在消费多个MessageQueue，所以为了不出现数据倾斜，也为了资源的合理分配利用，在Producer发送消息的时候，需要尽可能的将消息均匀的分发给多个MessageQueue。&lt;/p>
&lt;p>同时，上面那种一个Consumer消费了2个MessageQueue的情况，万一这台Consumer挂了呢？这两个MessageQueue不就没人消费了？&lt;/p>
&lt;p>以上两种情况分别是Producer端的负载均衡、Consumer端的负载均衡。&lt;/p>
&lt;h2 id="producer端负载均衡">Producer端负载均衡&lt;/h2>
&lt;p>关于Producer端上面的负载均衡，上面的流程图已经给了出来，并且给出了源码的验证。首先是容错策略，会去避开一段时间有问题的Broker，并且加上如果选择了上次的Broker，就会重新进行选择。&lt;/p>
&lt;h2 id="consumer端负载均衡">Consumer端负载均衡&lt;/h2>
&lt;p>首先Consumer端的负责均衡可以由两个对象触发：&lt;/p>
&lt;p>1）Broker&lt;/p>
&lt;p>2）Consumer自身&lt;/p>
&lt;p>Consumer 也会向所有的 Broker 发送心跳，将消息的消费组名称、订阅关系集合、消息的通信模式和客户端的ID等等。Broker 收到了 Consumer 的心跳之后，会将其存在 Broker 维护的一个 Manager 中，名字叫 ConsumerManager。当Broker监听到了 Consumer 数量发生了变动，就会通知 Consume r进行 Rebalance。&lt;/p>
&lt;p>但是如果 Broker 通知 Consumer 进行 Rebalance 的消息丢了呢？这也就是为什么需要第Consumer 自身进行触发的原因。Consumer会在启动的时候启动定时任务，周期性的执行rebalance操作。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_35.png" alt="20221231_rocketmq_35.png">&lt;/p>
&lt;p>默认是20秒执行一次。具体的代码如下。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_36.png" alt="20221231_rocketmq_36.png">&lt;/p>
&lt;h3 id="具体流程">具体流程&lt;/h3>
&lt;p>首先，Consumer的Rebalance会获取到本地缓存的Topic的全部数据，然后向Broker发起请求，拉取该Topic和ConsumerGroup下的所有的消费者信息。此处的Broker数据来源就是Consumer之前的心跳发送过去的数据。然后会对Topic中MessageQueue和消费者ID进行排序，然后用消息队列默认分配算法来进行分配，这里的默认分配策略是平均分配。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_37.png" alt="20221231_rocketmq_37.png">&lt;/p>
&lt;p>首先会均匀的按照类似分页的思想，将MessageQueue分配给Consumer，如果分配的不均匀，则会依次的将剩下的MessageQueue按照排序的顺序，从上往下的分配。所以在这里Consumer 1被分配到了4个MessageQueue，而Consumer 2被分配到了3个MessageQueue。&lt;/p>
&lt;p>Rebalance完了之后，会将结果和Consumer缓存的数据做对比，移除不在ReBalance结果中的MessageQueue，将原本没有的MessageQueue给新增到缓存中。&lt;/p>
&lt;h3 id="触发时机">触发时机&lt;/h3>
&lt;p>1）Consumer启动时 启动之后会立马进行Rebalance&lt;/p>
&lt;p>2）Consumer运行中 运行中会监听Broker发送过来的Rebalance消息，以及Consumer自身的定时任务触发的Rebalance&lt;/p>
&lt;p>3）Consumer停止运行 停止时没有直接的调用Rebalance，而是会通知Broker自己下线了，然后Broker会通知其余的Consumer进行Rebalance。&lt;/p>
&lt;p>换一个角度来分析，其实就是两个方面，一个是队列信息发生了变化，另一种是消费者发生了变化。&lt;/p>
&lt;h3 id="源码验证">源码验证&lt;/h3>
&lt;p>然后给出核心的代码验证，获取数据的逻辑如下&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_38.png" alt="20221231_rocketmq_38.png">&lt;/p>
&lt;p>验证了我们刚刚说的获取了本地的Topic数据缓存，和从Broker端拉取所有的ConsumerID。&lt;/p>
&lt;p>接下来是验证刚说的排序逻辑。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_39.png" alt="20221231_rocketmq_39.png">&lt;/p>
&lt;p>接下来是看判断结果是否发生了变化的源码。&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_40.png" alt="20221231_rocketmq_40.png">&lt;/p>
&lt;p>&lt;img src="../imgs/20221231_rocketmq_41.png" alt="20221231_rocketmq_41.png">&lt;/p>
&lt;p>可以看到，Consumer通知Broker策略，其本质上就是发送心跳，将更新后的数据通过心跳发送给所有的Broker。&lt;/p>
&lt;h1 id="延迟消息">延迟消息&lt;/h1>
&lt;h2 id="延迟消息功能">延迟消息功能&lt;/h2>
&lt;p>延迟消息的核心使用方法就是在 Message 中设定一个 MessageDelayLevel 参数，对应 18 个延迟级别。然后 Broker 中会创建一个默认的 Schedule_Topic 主题，这个主题下有 18 个队列，对应 18 个延迟级别。消息发过来之后，会把消息存入 Schedule_Topic 主题中对应的队列。然后等延迟消息到了，再转发到目标队列，推送给消费者进行消费。&lt;/p>
&lt;style>
.td-content .highlight {
margin-top: 0.5rem;
margin-bottom: 0.5rem;
}
.code-collapse1 {
overflow-y: auto;
max-height: 500px;
overflow-x: auto;
max-width: 100%;
}
&lt;/style>
&lt;div class="code-collapse1">
&lt;div class="highlight">&lt;div style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-plain" data-lang="plain">&lt;span style="display:flex;">&lt;span>msg.setDelayTimeLevel(2); // 设置延迟级别
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>延迟消息整体流程
&lt;img src="../imgs/20221231_rocketmq_42.png" alt="20221231_rocketmq_42.png">&lt;/p>
&lt;p> &lt;/p>
&lt;p> &lt;/p>
&lt;p>延迟消息的处理入口在 scheduleMessageService 这个组件中，它会在 broker 启动时也一起加载。&lt;/p>
&lt;h2 id="延迟消息写入">延迟消息写入&lt;/h2>
&lt;p>代码见 CommitLog.putMessage 方法&lt;/p>
&lt;p>在 CommitLog 写入消息时，会判断消息的延迟级别，然后修改 Message 的 Topic 和 Queue，达到转储 Message 的目的。&lt;/p>
&lt;p> &lt;/p>
&lt;h2 id="延迟消息转储到目标-topic">延迟消息转储到目标 Topic&lt;/h2>
&lt;p>核心服务是 ScheduleMessageService，也是 Broker 启动过程中的一个功能组件。&lt;/p>
&lt;p>然后 ScheduleMessageService 每隔 1 秒钟执行一个 executeOnTimeup 任务，将消息从延迟队列中写入正常 Topic 中。代码见 ScheduleMessageService 中的 DeliverDelayedMessageTimerTask.executeOnTimeup 方法。&lt;/p>
&lt;p> &lt;/p>
&lt;p>其中有个需要注意的点事 ScheduleMessageService 的 start 方法中，有一个很关键的 CAS 操作：&lt;/p>
&lt;style>
.td-content .highlight {
margin-top: 0.5rem;
margin-bottom: 0.5rem;
}
.code-collapse1 {
overflow-y: auto;
max-height: 500px;
overflow-x: auto;
max-width: 100%;
}
&lt;/style>
&lt;div class="code-collapse1">
&lt;div class="highlight">&lt;div style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-plain" data-lang="plain">&lt;span style="display:flex;">&lt;span>if (started.compareAndSet(false, true)) {
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>保证同一时间只会有一个 DeliveDelayedMessageTimerTask 执行。保证了消息安全的同时业限制了消息进行回传的效率。这也是很多互联网公司在使用 RocketMQ 时，对源码进行定制的一个重点。
 &lt;/p></description></item></channel></rss>