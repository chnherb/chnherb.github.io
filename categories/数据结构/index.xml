<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Herbdocs – 数据结构</title><link>/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</link><description>Recent content in 数据结构 on Herbdocs</description><generator>Hugo -- gohugo.io</generator><atom:link href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: 数据结构</title><link>/docs/60.%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/60.%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</guid><description>
&lt;h1 id="introduction">Introduction&lt;/h1>
&lt;p>数据结构&lt;/p></description></item><item><title>Docs: LSM树</title><link>/docs/60.%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/LSM%E6%A0%91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/60.%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/LSM%E6%A0%91/</guid><description>
&lt;h1 id="简介">简介&lt;/h1>
&lt;h2 id="背景">背景&lt;/h2>
&lt;p>NoSQL数据库中，RocksDB、LevelDB、HBase以及Prometheus等，其底层的存储引擎都是基于LSM树，这一数据结构对了解存储引擎至关重要。&lt;/p>
&lt;p>LSM树的核心特点是利用顺序写来提高写性能，但因为分层(此处分层是指的分为内存和文件两部分)的设计会稍微降低读性能，但是通过牺牲小部分读性能换来高性能写，使得LSM树成为非常流行的存储结构。&lt;/p>
&lt;h2 id="定义">定义&lt;/h2>
&lt;p>Log Structured Merge Trees(LSM) 日志结构合并树：&lt;/p>
&lt;ol>
&lt;li>LSM树是一个横跨内存和磁盘的，包含多颗&amp;quot;子树&amp;quot;的一个森林。&lt;/li>
&lt;li>LSM树分为Level 0，Level 1，Level 2 ... Level n 多颗子树，其中只有Level 0在内存中，其余Level 1-n在磁盘中。&lt;/li>
&lt;li>内存中的Level 0子树一般采用排序树（红黑树/AVL树）、跳表或者TreeMap等这类有序的数据结构，方便后续顺序写磁盘。&lt;/li>
&lt;li>磁盘中的Level 1-n子树，本质是数据排好序后顺序写到磁盘上的文件，只是叫做树而已。&lt;/li>
&lt;li>每一层的子树都有一个阈值大小，达到阈值后会进行合并，合并结果写入下一层。&lt;/li>
&lt;li>只有内存中数据允许原地更新，磁盘上数据的变更只允许追加写，不做原地更新。
&lt;img src="../imgs/20221203_lsm_1.png" alt="20221203_lsm_1.png">&lt;/li>
&lt;/ol>
&lt;p>（图1 LSM树的组成与定义）&lt;/p>
&lt;ul>
&lt;li>图1中分成了左侧绿色的内存部分和右侧蓝色的磁盘部分（定义1）。&lt;/li>
&lt;li>图1左侧绿色的内存部分只包含Level 0树，右侧蓝色的磁盘部分则包含Level 1-n等多棵&amp;quot;树&amp;quot;（定义2）&lt;/li>
&lt;li>图1左侧绿色的内存部分中Level 0是一颗二叉排序树（定义3）。注意这里的&lt;strong>有序性&lt;/strong>，该性质决定了LSM树优异的读写性能。&lt;/li>
&lt;li>图1右侧蓝色的磁盘部分所包含的Level 1到Level n多颗树，虽然叫做“树”，但本质是按数据key排好序后，顺序写在磁盘上的一个个文件（定义4） ，注意这里再次出现了&lt;strong>有序性&lt;/strong>。&lt;/li>
&lt;li>内存中的Level 0树在达到阈值后，会在内存中遍历排好序的Level 0树并顺序写入磁盘的Level 1。同样的，在磁盘中的Level n（n&amp;gt;0）达到阈值时，则会将Level n层的多个文件进行归并，写入Level n+1层。（定义5）&lt;/li>
&lt;li>除了内存中的Level 0层做原地更新外，对已写入磁盘上的数据，都采用Append形式的磁盘顺序写，即更新和删除操作并不去修改老数据，只是简单的追加新数据。图1中右侧蓝色的磁盘部分，Level 1和Level 2均包含key为2的数据，同时图1左侧绿色内存中的Level 0树也包含key为2的数据节点。（定义6）
内存缓存（memtable）会通过写WAL的方式备份到磁盘，用来恢复数据，防止数据丢失。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="../imgs/20221203_lsm_2.JPG" alt="20221203_lsm_2.JPG">
论文：&lt;a href="http://ranger.uta.edu/~sjiang/pubs/papers/wang14-LSM-SDF.pdf">An Efficient Design and Implementation of LSM-Tree based Key-Value Store on Open-Channel SSD&lt;/a>&lt;/p>
&lt;h2 id="组成">组成&lt;/h2>
&lt;p>&lt;img src="../imgs/20221203_lsm_3.png" alt="20221203_lsm_3.png">&lt;/p>
&lt;p>LSM树有以下三个重要组成部分：&lt;/p>
&lt;ol>
&lt;li>MemTable&lt;/li>
&lt;/ol>
&lt;p>MemTable是在内存中的数据结构，用于保存最近更新的数据，会按照Key有序地组织这些数据，LSM树对于具体如何组织有序地组织数据并没有明确的数据结构定义，例如Hbase使跳跃表来保证内存中key的有序。&lt;/p>
&lt;p>因为数据暂时保存在内存中，内存并不是可靠存储，如果断电会丢失数据，因此通常会通过WAL(Write-ahead logging，预写式日志)的方式来保证数据的可靠性。&lt;/p>
&lt;p>这个内存中 MemTable 不能无限地往里写，一是内存的容量毕竟有限，另外，MemTable 太大了读写性能都会下降。所以，MemTable 有一个固定的上限大小，一般是 32M。MemTable 写满之后，就被转换成 Immutable MemTable，然后再创建一个空的 MemTable 继续写。这个 Immutable MemTable，也就是只读的 MemTable，它和 MemTable 的数据结构完全一样，唯一的区别就是不允许再写入了。&lt;/p>
&lt;ol start="2">
&lt;li>Immutable MemTable&lt;/li>
&lt;/ol>
&lt;p>当 MemTable达到一定大小后，会转化成Immutable MemTable。Immutable MemTable是将转MemTable变为SSTable的一种中间状态。写操作由新的MemTable处理，在转存过程中不阻塞数据更新操作。&lt;/p>
&lt;p>Immutable MemTable 也不能在内存中无限地占地方，会有一个后台线程，不停地把 Immutable MemTable 复制到磁盘文件中，然后释放内存空间。每个 Immutable MemTable 对应一个磁盘文件，MemTable 的数据结构跳表本身就是一个有序表，写入的文件也是一个按照 Key 排序的结构，这些文件就是 SSTable。把 MemTable 写入 SSTable 这个写操作，因为它是把整块内存写入到整个文件中，这同样是一个顺序写操作。&lt;/p>
&lt;ol start="3">
&lt;li>SSTable(Sorted String Table)&lt;/li>
&lt;/ol>
&lt;p>有序键值对集合，是LSM树组在磁盘中的数据结构。为了加快SSTable的读取，可以通过建立key的索引以及布隆过滤器来加快key的查找。&lt;/p>
&lt;p>SSTable 被分为很多层，越往上层，文件越少，越往底层，文件越多。每一层的容量都有一个固定的上限，一般来说，下一层的容量是上一层的 10 倍。当某一层写满了，就会触发后台线程往下一层合并，数据合并到下一层之后，本层的 SSTable 文件就可以删除掉了。合并的过程也是排序的过程，除了 Level 0（第 0 层，也就是 MemTable 直接 dump 出来的磁盘文件所在的那一层。）以外，每一层内的文件都是有序的，文件内的 KV 也是有序的，这样就比较便于查找了。&lt;/p>
&lt;h1 id="数据操作">数据操作&lt;/h1>
&lt;h2 id="插入操作">插入操作&lt;/h2>
&lt;p>LSM树的插入较简单，直接往内存中的Level 0排序树按照顺序插入即可。并不关心该数据是否已经在内存或磁盘中存在。已经存在该数据的话，则场景转换成更新操作。&lt;/p>
&lt;p>该操作复杂度为树高log(n)，n是Level 0树的数据量，可见代价很低，能实现极高的写吞吐量。&lt;/p>
&lt;h2 id="删除操作">删除操作&lt;/h2>
&lt;p>LSM树的删除操作并不是直接删除数据，而是通过一种叫“墓碑标记”的特殊数据来标识数据的删除。&lt;/p>
&lt;p>删除操作分为三种情况：&lt;/p>
&lt;ul>
&lt;li>待删除数据在内存中&lt;/li>
&lt;li>待删除数据在磁盘中&lt;/li>
&lt;li>该数据根本不存在&lt;/li>
&lt;/ul>
&lt;h3 id="待删除数据在内存中">待删除数据在内存中&lt;/h3>
&lt;p>删除数据时不能简单地将Level 0树中的节点删除，而是应该采用墓碑标记将其覆盖&lt;/p>
&lt;p>为什么不能直接删除而是要用墓碑标记覆盖呢？&lt;/p>
&lt;blockquote>
&lt;/blockquote>
&lt;h3 id="待删除数据在磁盘中">待删除数据在磁盘中&lt;/h3>
&lt;p>不直接去修改磁盘上的数据（理都不理它），而是直接向内存中的Level 0树中插入墓碑标记即可。&lt;/p>
&lt;h3 id="数据不存在">数据不存在&lt;/h3>
&lt;p>这种情况等价于在内存的Level 0树中新增一条墓碑标记，场景转换为在内存中插入墓碑标记操作。&lt;/p>
&lt;p>综合看待上述三种情况，发现不论数据有没有、在哪里，删除操作都是等价于向Level 0树中写入墓碑标记。该操作复杂度为树高log(n)，代价很低。&lt;/p>
&lt;h2 id="修改操作">修改操作&lt;/h2>
&lt;p>LSM树的修改操作和删除操作很像，也是分为三种情况：&lt;/p>
&lt;ul>
&lt;li>待修改数据在内存中&lt;/li>
&lt;li>待修改数据在磁盘中&lt;/li>
&lt;li>该数据根本不存在&lt;/li>
&lt;/ul>
&lt;h3 id="待修改数据在内存中">待修改数据在内存中&lt;/h3>
&lt;p>直接定位到内存中Level 0树上黄色的老的key的位置，将其覆盖即可。&lt;/p>
&lt;h3 id="待修改数据在磁盘中">待修改数据在磁盘中&lt;/h3>
&lt;p>LSM树并不会去磁盘中的Level 1树上原地更新老的key的数据，而是直接将新的修改的节点插入内存中的Level 0树中。&lt;/p>
&lt;h3 id="数据不存在-1">数据不存在&lt;/h3>
&lt;p>同上，直接向内存中的Level 0树插入新的数据即可。&lt;/p>
&lt;p>综上三种情况可以看出，修改操作都是对内存中Level 0进行覆盖/新增操作。该操作复杂度为树高log(n)，代价很低。&lt;/p>
&lt;p>LSM树的增加、删除、修改（这三个都属于写操作）都是在内存中倒腾，完全没涉及到磁盘操作，所以速度飞快，写吞吐量高。&lt;/p>
&lt;h2 id="查询操作">查询操作&lt;/h2>
&lt;p>LSM树的查询操作会按顺序查找Level 0、Level 1、Level 2 ... Level n 每一颗树，一旦匹配便返回目标数据，不再继续查询。该策略保证了查到的一定是目标key最新版本的数据。&lt;/p>
&lt;p>查询场景分析：&lt;/p>
&lt;ul>
&lt;li>待查询数据在内存中&lt;/li>
&lt;li>待查询数据在磁盘中
综合上述两种情况，LSM树的查询操作相对来说代价比较高，需要从Level 0到Level n一直顺序查下去。极端情况是LSM树中不存在该数据，则需要把整个库从Level 0到Level n给扫了一遍，然后返回查无此人（当然可以通过 布隆过滤器 + 建立稀疏索引 来优化查询操作）。代价大于以B/B+树为基本数据结构的传统RDB存储引擎。&lt;/li>
&lt;/ul>
&lt;h2 id="合并操作">合并操作&lt;/h2>
&lt;p>合并操作（compaction）是LSM树的核心（毕竟LSM树全称是日志结构合并树）。&lt;/p>
&lt;p>之所以在增、删、改、查这四个基本操作之外还需要合并操作：&lt;/p>
&lt;ol>
&lt;li>因为内存不是无限大，Level 0树达到阈值时，需要将数据从内存刷到磁盘中，这是合并操作的第一个场景；&lt;/li>
&lt;li>需要对磁盘上达到阈值的顺序文件进行归并，并将归并结果写入下一层，归并过程中会清理重复的数据和被删除的数据(墓碑标记)。
分别对上述两个场景进行分析：&lt;/li>
&lt;/ol>
&lt;h3 id="内存数据写入磁盘">内存数据写入磁盘&lt;/h3>
&lt;p>内存中Level 0树在达到阈值后，归并写入磁盘Level 1树的场景。&lt;/p>
&lt;p>对内存中的Level 0树进行&lt;strong>中序遍历&lt;/strong>，将数据&lt;strong>顺序写入&lt;/strong>磁盘的Level 1层即可，可以看到因为Level 0树是已经排好序的，所以写入的Level 1中的新块（追加）也是有序的（有序性保证了查询和归并操作的高效）。此时磁盘的Level 1层有两个Block块（追加）。&lt;/p>
&lt;h3 id="磁盘多个块归并">磁盘多个块归并&lt;/h3>
&lt;p>磁盘中Level 1层达到阈值时，对其包含的两个Block块进行归并，并将归并结果写入Level 2层的过程。&lt;/p>
&lt;p>如果数据同时存在于较老的Block和较新的Block中。而归并的过程是保留较新的数据。&lt;/p>
&lt;p>综上可以看到，以上两个场景由于原始数据都是有序的，因此归并的过程只需要对数据集进行一次扫描即可，复杂度为O(n)。&lt;/p>
&lt;h1 id="compact策略">Compact策略&lt;/h1>
&lt;p>Compact操作是十分关键的操作，否则SSTable数量会不断膨胀。在Compact策略上，主要介绍两种基本策略：size-tiered和leveled。&lt;/p>
&lt;p>不过在介绍这两种策略之前，先介绍三个比较重要的概念，事实上不同的策略就是围绕这三个概念之间做出权衡和取舍。&lt;/p>
&lt;blockquote>
&lt;p>1）读放大:读取数据时实际读取的数据量大于真正的数据量。例如在LSM树中需要先在MemTable查看当前key是否存在，不存在继续从SSTable中寻找。
2）写放大:写入数据时实际写入的数据量大于真正的数据量。例如在LSM树中写入时可能触发Compact操作，导致实际写入的数据量远大于该key的数据量。
3）空间放大:数据实际占用的磁盘空间比数据的真正大小更多。上面提到的冗余存储，对于一个key来说，只有最新的那条记录是有效的，而之前的记录都是可以被清理回收的。&lt;/p>
&lt;/blockquote>
&lt;h2 id="size-tiered-策略">size-tiered 策略&lt;/h2>
&lt;p>size-tiered策略保证每层SSTable的大小相近，同时限制每一层SSTable的数量。如上图，每层限制SSTable为N，当每层SSTable达到N后，则触发Compact操作合并这些SSTable，并将合并后的结果写入到下一层成为一个更大的sstable。&lt;/p>
&lt;p>当层数达到一定数量时，最底层的单个SSTable的大小会变得非常大。并且size-tiered策略会导致空间放大比较严重。即使对于同一层的SSTable，每个key的记录是可能存在多份的，只有当该层的SSTable执行compact操作才会消除这些key的冗余记录。&lt;/p>
&lt;h2 id="leveled策略">leveled策略&lt;/h2>
&lt;p>leveled策略也是采用分层的思想，每一层限制总文件的大小。&lt;/p>
&lt;p>但是跟size-tiered策略不同的是，leveled会将每一层切分成多个大小相近的SSTable。这些SSTable是这一层是全局有序的，意味着一个key在每一层至多只有1条记录，不存在冗余记录。之所以可以保证全局有序，是因为合并策略和size-tiered不同。&lt;/p>
&lt;h1 id="优缺点">优缺点&lt;/h1>
&lt;p>可以看到LSM树将增、删、改这三种操作都转化为内存insert + 磁盘顺序写(当Level 0满的时候)，通过这种方式得到了无与伦比的写吞吐量。&lt;/p>
&lt;p>LSM树的查询能力则相对被弱化，相比于B+树的最多3~4次磁盘IO，LSM树则要从Level 0一路查询Level n，极端情况下等于做了全表扫描。（即便做了稀疏索引，也是lg(N0)+lg(N1)+...+lg(Nn)的复杂度，大于B+树的lg(N0+N1+...+Nn)的时间复杂度）。&lt;/p>
&lt;p>LSM树只append追加不原地修改的特性引入了归并操作，归并操作涉及到大量的磁盘IO，比较消耗性能，需要合理设置触发该操作的参数。&lt;/p>
&lt;p>综上可以给出LSM树的优缺点：&lt;/p>
&lt;p>优：增、删、改操作飞快，写吞吐量极大。&lt;/p>
&lt;p>缺：读操作性能相对被弱化；不擅长区间范围的读操作； 归并操作较耗费资源。&lt;/p>
&lt;p>LSMTree的增、删、改、查四种基本操作的时间复杂度分析如下所示：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">操作&lt;/th>
&lt;th style="text-align:left">平均代价&lt;/th>
&lt;th style="text-align:left">最坏情况代价&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">插入&lt;/td>
&lt;td style="text-align:left">1&lt;/td>
&lt;td style="text-align:left">1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">删除&lt;/td>
&lt;td style="text-align:left">1&lt;/td>
&lt;td style="text-align:left">1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">修改&lt;/td>
&lt;td style="text-align:left">1&lt;/td>
&lt;td style="text-align:left">1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">查找&lt;/td>
&lt;td style="text-align:left">lgN&lt;/td>
&lt;td style="text-align:left">lgN&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h1 id="小结">小结&lt;/h1>
&lt;p>LSM树的设计原则：&lt;/p>
&lt;ul>
&lt;li>先内存再磁盘&lt;/li>
&lt;li>内存原地更新&lt;/li>
&lt;li>磁盘追加更新&lt;/li>
&lt;li>归并保留新值&lt;/li>
&lt;/ul>
&lt;h1 id="reference">Reference&lt;/h1>
&lt;p>&lt;a href="https://zhuanlan.zhihu.com/p/415799237">深入浅出LSM树&lt;/a>&lt;/p></description></item><item><title>Docs: 红黑树</title><link>/docs/60.%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E7%BA%A2%E9%BB%91%E6%A0%91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/60.%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E7%BA%A2%E9%BB%91%E6%A0%91/</guid><description>
&lt;h1 id="简介">简介&lt;/h1>
&lt;p>红黑树（Red-Black Tree），简称 R-B Tree。它是一种不严格的平衡二叉查找树。&lt;/p>
&lt;h1 id="性质">性质&lt;/h1>
&lt;p>红黑树的性质（重点）：&lt;/p>
&lt;p>1、每个节点不是红色就是黑色&lt;/p>
&lt;p>2、不可能有连在一起的红色节点&lt;/p>
&lt;p>3、根节点都是黑色 root&lt;/p>
&lt;p>4、每个红色节点节点的两个子节点都是黑色，叶子节点（NIL节点）都是黑色：出度为0满足了性质就可以近似的平衡了&lt;/p>
&lt;p>5、从任意节点到其每个叶子的所有路径都包含相同数据的黑色节点&lt;/p>
&lt;p>正式因为规则限制，才保证了红黑树的自平衡。红黑树从根到叶子的最长路径不会超过最短路径的2倍。&lt;/p>
&lt;h1 id="变换规则">变换规则&lt;/h1>
&lt;p>为了满足红黑树的性质，有3种变换规则：所有插入的点默认为红色&lt;/p>
&lt;p>1、改变颜色：当前节点的父节点是红色，且叔叔节点（祖父节点的另一个子节点）也是红色&lt;/p>
&lt;p>（1）把父节点设为黑色&lt;/p>
&lt;p>（2）把叔叔节点也设为黑色&lt;/p>
&lt;p>（3）把爷爷节点（父节点的父节点）设为红色&lt;/p>
&lt;p>（4）把指针定义到爷爷节点设为当前要操作的节点&lt;/p>
&lt;p>2、左旋：当前父节点是红色、叔叔节点是黑色，且当前的节点是右子树。&lt;/p>
&lt;p>（1）以父节点作为左旋&lt;/p>
&lt;p>3、右旋：当前父节点是红色，叔叔节点时黑色，且当前的节点是左子树。&lt;/p>
&lt;p>（1）把父节点变为黑色&lt;/p>
&lt;p>（2）把爷爷节点变为红色&lt;/p>
&lt;p>（3）以爷爷节点旋转&lt;/p>
&lt;p>示例：插入6&lt;/p>
&lt;p>&lt;img src="../imgs/20221228_redblacktree_1.jpeg" alt="20221228_redblacktree_1.jpeg">&lt;/p>
&lt;p>&lt;img src="../imgs/20221228_redblacktree_2.jpeg" alt="20221228_redblacktree_2.jpeg">&lt;/p>
&lt;h1 id="应用">应用&lt;/h1>
&lt;p>JDK的集合类TreeMap和TreeSet底层就是红黑树来实现的，在JDK8中，连HashMap也用到了红黑树。&lt;/p></description></item><item><title>Docs: 跳表</title><link>/docs/60.%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E8%B7%B3%E8%A1%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/60.%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E8%B7%B3%E8%A1%A8/</guid><description>
&lt;h1 id="简介">简介&lt;/h1>
&lt;p>跳表（SkipList）是一个随机化的数据结构，可以被看做二叉树的一个变种，它在性能上和红黑树，AVL树不相上下，但是跳表的原理非常简单，目前在Redis和LeveIDB中都有用到。&lt;/p>
&lt;h1 id="定义">定义&lt;/h1>
&lt;p>增加了向前指针的链表叫作跳表。跳表全称叫做跳跃表，简称跳表。跳表是一个随机化的数据结构，实质就是一种可以进行二分查找的有序链表。跳表在原有的有序链表上面增加了多级索引，通过索引来实现快速查找。跳表不仅能提高搜索性能，同时也可以提高插入和删除操作的性能。&lt;/p>
&lt;h1 id="跳表的由来">跳表的由来&lt;/h1>
&lt;p>对于一个单链表来讲，即便链表中存储的数据是有序的，如果想在其中查找某个数据，也只能从头到尾遍历链表。这样查找效率很低，时间复杂度很高是 O(n)。&lt;/p>
&lt;p>如果像下图中那样，对链表建立一级“索引”，查找起来会更快一些，每两个结点提取一个结点到上一级，把抽出来的那一级叫做索引或索引层。图中的 down 表示 down 指针，指向下一级结点。&lt;/p>
&lt;p>&lt;img src="../imgs/20221228_skiplist_1.png" alt="20221228_skiplist_1.png">&lt;/p>
&lt;p>从这个例子可以看出，加来一层索引之后，查找一个结点需要遍历的结点个数减少了，即查找效率提高了。&lt;/p>
&lt;p>跟前面建立第一级索引的方式相似，在第一级索引的基础之上，每两个结点就抽出一个结点到第二级索引。现在我们再来查找 16，只需要遍历 6 个结点了，需要遍历的结点数量又减少了。&lt;/p>
&lt;p>&lt;img src="../imgs/20221228_skiplist_2.png" alt="20221228_skiplist_2.png">&lt;/p>
&lt;p>这种链表加多级索引的结构，就是跳表。跳表在原有的有序链表上面增加了多级索引，通过索引来实现快速查找。首先在最高级索引上查找最后一个小于当前查找元素的位置，然后再跳到次高级索引继续查找，直到跳到最底层为止，这时候以及十分接近要查找的元素的位置了(如果查找元素存在的话)。由于根据索引可以一次跳过多个元素，所以跳查找的查找速度也就变快了。&lt;/p>
&lt;h1 id="复杂度">复杂度&lt;/h1>
&lt;h2 id="时间复杂度">时间复杂度&lt;/h2>
&lt;p>按照上面讲的，每两个结点会抽出一个结点作为上一级索引的结点，那第一级索引的结点个数大约就是 n/2，第二级索引的结点个数大约就是 n/4，第三级索引的结点个数大约就是 n/8，依次类推，也就是说，&lt;strong>第 k 级索引的结点个数是第 k-1 级索引的结点个数的 1/2，那第 k级索引结点的个数就是 n/(2k)&lt;/strong>。&lt;/p>
&lt;p>假设索引有 h 级，最高级的索引有 2 个结点。通过上面的公式，可以得到 n/(2^h)=2，从而求得 h=log2(n)-1（log以2为底的n）。如果包含原始链表这一层，整个跳表的高度就是 log2(n)。我们在跳表中查询某个数据的时候，如果每一层都要遍历 m 个结点，那在跳表中查询一个数据的时间复杂度就是 O(m*logn)。&lt;/p>
&lt;p>假设要查找的数据是 x，在第 k 级索引中，遍历到 y 结点之后，发现 x 大于 y，小于后面的结点 z，所以通过 y 的 down 指针，从第 k 级索引下降到第 k-1 级索引。在第 k-1 级索引中，y 和 z 之间只有 3 个结点（包含 y 和 z），所以在 K-1 级索引中最多只需要遍历 3 个结点，依次类推，每一级索引都最多只需要遍历 3 个结点。&lt;/p>
&lt;p>因此，&lt;strong>m 等于 3&lt;/strong>。所以&lt;strong>在跳表中查询任意数据的时间复杂度就是 O(logn)&lt;/strong>。这个查找的时间复杂度跟二分查找是一样的。&lt;/p>
&lt;h2 id="空间复杂度">空间复杂度&lt;/h2>
&lt;p>假设原始链表大小为 n，第一级索引大约有 n/2 个结点，第二级索引大约有 n/4 个结点，以此类推，每上升一级就减少一半，直到剩下 2 个结点。如果把每层索引的结点数写出来，就是一个等比数列。&lt;/p>
&lt;p>这几级索引的结点总和就是 n/2+n/4+n/8…+8+4+2=n-2。所以，&lt;strong>跳表的空间复杂度是 O(n)&lt;/strong>。&lt;/p>
&lt;p>前面都是每两个结点抽一个结点到上级索引，如果每三个结点或五个结点，抽一个结点到上级索引，就不用那么多索引结点了。&lt;/p>
&lt;p>可以看出，第一级索引需要大约 n/3 个结点，第二级索引需要大约 n/9 个结点。每往上一级，索引结点个数都除以 3。通过等比数列求和公式，总的索引结点大约就是 n/3+n/9+n/27+...+9+3+1=n/2。尽管空间复杂度还是 O(n)，但比上面的每两个结点抽一个结点的索引构建方法，要减少了一半的索引结点存储空间。&lt;/p>
&lt;h1 id="操作">操作&lt;/h1>
&lt;p>跳表这个动态数据结构，不仅支持查找操作，还支持动态的插入、删除操作，而且插入、删除操作的时间复杂度也是 O(logn)。&lt;/p>
&lt;h2 id="插入">插入&lt;/h2>
&lt;p>为了保证原始链表中数据的有序性，需要先找到要插入的位置，这个查找操作就会比较耗时。&lt;/p>
&lt;p>对于跳表来说，查找某个结点的时间复杂度是 O(logn)，所以这里查找某个数据应该插入的位置，方法也是类似的，时间复杂度也是 O(logn)。&lt;/p>
&lt;h2 id="删除">删除&lt;/h2>
&lt;p>如果要删除的结点在索引中也有出现，除了要删除原始链表中的结点，还要删除索引中的。因为单链表中的删除操作需要拿到要删除结点的前驱结点，然后通过指针操作完成删除。所以在查找要删除的结点的时候，一定要获取前驱结点。当然，如果用的是双向链表，就不需要考虑这个问题了。&lt;/p>
&lt;h1 id="跳表索引动态更新">跳表索引动态更新&lt;/h1>
&lt;p>当不停地往跳表中插入数据时，如果不更新索引，就有可能出现某 2 个索引结点之间数据非常多的情况。极端情况下，跳表还会退化成单链表。&lt;/p>
&lt;p>&lt;img src="../imgs/20221228_skiplist_3.png" alt="20221228_skiplist_3.png">&lt;/p>
&lt;p>作为一种动态数据结构，需要某种手段来维护索引与原始链表大小之间的平衡，即如果链表中结点多了，索引结点也就相应增加，避免复杂度退化，以及查找、插入、删除操作性能下降。像红黑树、AVL 树这样平衡二叉树，它们是通过左右旋的方式保持左右子树的大小平衡，而跳表是通过随机函数来维护前面提到的“平衡性”。&lt;/p>
&lt;h2 id="随机函数">随机函数&lt;/h2>
&lt;p>通过一个随机函数，来决定将这个结点插入到哪几级索引中，比如随机函数生成了值 K，那就将这个结点添加到第一级到第 K 级这 K 级索引中。&lt;/p>
&lt;p>&lt;img src="../imgs/20221228_skiplist_4.png" alt="20221228_skiplist_4.png">&lt;/p>
&lt;p>随机函数的选择很有讲究，从概率上来讲，能够保证跳表的索引大小和数据大小平衡性，不至于性能过度退化。随机函数的选择就不展开了。&lt;/p>
&lt;h1 id="faq">FAQ&lt;/h1>
&lt;p>&lt;strong>为什么 Redis 要用跳表来实现有序集合，而不是红黑树？&lt;/strong>&lt;/p>
&lt;p>Redis 中的有序集合是通过跳表来实现的，严格来讲还用到了散列表。Redis 的开发手册中有序集合支持的核心操作主要有下面这几个：&lt;/p>
&lt;ul>
&lt;li>插入一个数据；&lt;/li>
&lt;li>删除一个数据；&lt;/li>
&lt;li>查找一个数据；&lt;/li>
&lt;li>按照区间查找数据（比如查找值在[100, 200]之间的数据）；&lt;/li>
&lt;li>迭代输出有序序列。
其中，插入、删除、查找以及迭代输出有序序列这几个操作，红黑树也可以完成，时间复杂度跟跳表是一样的。但是，&lt;strong>按照区间来查找数据这个操作，红黑树的效率没有跳表高&lt;/strong>。对于按照区间查找数据这个操作，跳表可以做到 O(logn) 的时间复杂度定位区间的起点，然后在原始链表中顺序往后遍历就可以了。这样做非常高效。&lt;/li>
&lt;/ul>
&lt;p>Redis 用跳表来实现有序集合还有其他原因，比如，跳表更容易代码实现（虽然跳表的实现也不简单，但比起红黑树来说还是简单、可读性好，不容易出错）。另外跳表更加灵活，可以通过改变索引构建策略，有效平衡执行效率和内存消耗。&lt;/p>
&lt;p>不过，跳表也不能完全替代红黑树。因为红黑树比跳表的出现要早一些，很多编程语言中的 Map 类型都是通过红黑树来实现的。可以直接拿来使用，不用自己去实现，但是跳表并没有一个现成的实现，需要自己实现。&lt;/p></description></item><item><title>Docs: 算法与数据结构</title><link>/docs/60.%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/60.%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</guid><description>
&lt;h1 id="introduction">Introduction&lt;/h1>
&lt;p>算法与数据结构&lt;/p></description></item></channel></rss>